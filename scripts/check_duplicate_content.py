"""
===============================================================================
é‡è¤‡å…§å®¹æª¢æ¸¬å·¥å…· (Duplicate Content Detector)
===============================================================================

ğŸ“‹ è…³æœ¬ç”¨é€”ï¼š
    æœ¬è…³æœ¬ç”¨æ–¼æª¢æ¸¬ç›®éŒ„ä¸­çš„é‡è¤‡æª”æ¡ˆï¼Œç‰¹åˆ¥é‡å° Excel æª”æ¡ˆé€²è¡Œå…§å®¹ç´šåˆ¥çš„é‡è¤‡æª¢æ¸¬ã€‚
    é€éæª”æ¡ˆå¤§å°åˆ†çµ„å’Œå…§å®¹é›œæ¹Šå€¼æ¯”è¼ƒï¼Œè­˜åˆ¥çœŸæ­£é‡è¤‡çš„æª”æ¡ˆï¼Œå¹«åŠ©æ¸…ç†å†—é¤˜è³‡æ–™ã€‚

ğŸ¯ æ ¸å¿ƒé‡é»ï¼š
    1. æ™ºèƒ½é‡è¤‡æª¢æ¸¬ï¼šå…ˆæŒ‰æª”æ¡ˆå¤§å°åˆ†çµ„ï¼Œå†é€²è¡Œå…§å®¹ç´šåˆ¥çš„é›œæ¹Šå€¼æ¯”è¼ƒ
    2. Excel å…§å®¹è§£æï¼šç›´æ¥è®€å– Excel æª”æ¡ˆå…§å®¹é€²è¡Œé›œæ¹Šè¨ˆç®—ï¼Œé¿å…æ ¼å¼å·®ç•°èª¤åˆ¤
    3. å¤šå±¤ç´šæª¢æŸ¥ï¼šæª”æ¡ˆå¤§å° â†’ å…§å®¹é›œæ¹Š â†’ é‡è¤‡æª”æ¡ˆè­˜åˆ¥
    4. æ¸…ç†å»ºè­°ï¼šæä¾›å…·é«”çš„æª”æ¡ˆæ¸…ç†ç­–ç•¥å’Œå»ºè­°

ğŸ”§ ä¸»è¦åŠŸèƒ½ï¼š
    - æƒææŒ‡å®šç›®éŒ„ä¸‹çš„æ‰€æœ‰æª”æ¡ˆ
    - æŒ‰æª”æ¡ˆå¤§å°é€²è¡Œåˆ†çµ„
    - å°ç›¸åŒå¤§å°çš„æª”æ¡ˆé€²è¡Œå…§å®¹é›œæ¹Šå€¼è¨ˆç®—
    - è­˜åˆ¥å…§å®¹å®Œå…¨ç›¸åŒçš„é‡è¤‡æª”æ¡ˆ
    - æä¾›è©³ç´°çš„é‡è¤‡æª”æ¡ˆå ±å‘Šå’Œæ¸…ç†å»ºè­°

ğŸ“Š æª¢æ¸¬é‚è¼¯ï¼š
    1. æª”æ¡ˆå¤§å°åˆ†çµ„ï¼šå°‡ç›¸åŒå¤§å°çš„æª”æ¡ˆæ­¸ç‚ºä¸€çµ„
    2. å…§å®¹é›œæ¹Šè¨ˆç®—ï¼šå°æ¯çµ„æª”æ¡ˆè¨ˆç®—å…§å®¹é›œæ¹Šå€¼
    3. é‡è¤‡è­˜åˆ¥ï¼šæ‰¾å‡ºå…·æœ‰ç›¸åŒé›œæ¹Šå€¼çš„æª”æ¡ˆ
    4. çµæœå ±å‘Šï¼šé¡¯ç¤ºé‡è¤‡æª”æ¡ˆçš„è©³ç´°è³‡è¨Š

ğŸš€ ä½¿ç”¨å ´æ™¯ï¼š
    - å‚™ä»½ç›®éŒ„æ¸…ç†
    - é‡è¤‡è³‡æ–™æª”æ¡ˆè­˜åˆ¥
    - è³‡æ–™æ­¸æª”å‰çš„å†—é¤˜æª¢æŸ¥
    - ç³»çµ±å„²å­˜ç©ºé–“å„ªåŒ–

ğŸ“ é è¨­æª¢æŸ¥ç›®éŒ„ï¼š
    - data_raw/etmall/backupï¼ˆæ±æ£®è³¼ç‰©å‚™ä»½ç›®éŒ„ï¼‰
    - å¯ä¿®æ”¹ main() å‡½æ•¸ä¸­çš„ backup_dir è®Šæ•¸

ğŸ” æª¢æ¸¬æ–¹æ³•ï¼š
    - Excel æª”æ¡ˆï¼šç›´æ¥è®€å–å…§å®¹ä¸¦è¨ˆç®—é›œæ¹Šå€¼
    - å…¶ä»–æª”æ¡ˆï¼šä½¿ç”¨æª”æ¡ˆ MD5 é›œæ¹Šå€¼
    - æ”¯æ´æ ¼å¼ï¼š.xlsx, .xls ç­‰ Excel æ ¼å¼

ğŸ“ˆ è¼¸å‡ºè³‡è¨Šï¼š
    - ç¸½æª”æ¡ˆæ•¸é‡çµ±è¨ˆ
    - ç›¸åŒå¤§å°æª”æ¡ˆåˆ†çµ„
    - å…§å®¹é‡è¤‡æª”æ¡ˆè©³ç´°åˆ—è¡¨
    - é‡è¤‡æª”æ¡ˆç¸½æ•¸çµ±è¨ˆ
    - æ¸…ç†ç­–ç•¥å»ºè­°

ä½œè€…ï¼šEC Data Pipeline åœ˜éšŠ
ç‰ˆæœ¬ï¼šv1.0.0
æ›´æ–°æ—¥æœŸï¼š2025-08-19
===============================================================================
"""

import os
import hashlib
from pathlib import Path
import pandas as pd
from collections import defaultdict

def get_file_hash(file_path):
    """è¨ˆç®—æª”æ¡ˆçš„ MD5 é›œæ¹Šå€¼"""
    hash_md5 = hashlib.md5()
    try:
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    except Exception as e:
        print(f"ç„¡æ³•è®€å–æª”æ¡ˆ {file_path}: {e}")
        return None

def get_excel_content_hash(file_path):
    """è®€å– Excel æª”æ¡ˆå…§å®¹ä¸¦è¨ˆç®—é›œæ¹Šå€¼"""
    try:
        if file_path.suffix.lower() == '.xlsx':
            df = pd.read_excel(file_path, engine='openpyxl')
        else:
            df = pd.read_excel(file_path, engine='xlrd')
        
        # å°‡ DataFrame è½‰æ›ç‚ºå­—ä¸²ä¸¦è¨ˆç®—é›œæ¹Š
        content_str = df.to_string(index=False)
        return hashlib.md5(content_str.encode('utf-8')).hexdigest()
    except Exception as e:
        print(f"ç„¡æ³•è®€å– Excel æª”æ¡ˆ {file_path}: {e}")
        return None

def check_duplicates(directory):
    """æª¢æŸ¥ç›®éŒ„ä¸‹çš„é‡è¤‡æª”æ¡ˆ"""
    print(f"æª¢æŸ¥ç›®éŒ„ï¼š{directory}")
    print("=" * 60)
    
    # æ”¶é›†æ‰€æœ‰æª”æ¡ˆ
    files = []
    for file_path in Path(directory).glob("*"):
        if file_path.is_file():
            files.append(file_path)
    
    print(f"ç¸½å…±æ‰¾åˆ° {len(files)} å€‹æª”æ¡ˆ")
    print()
    
    # æŒ‰æª”æ¡ˆå¤§å°åˆ†çµ„
    size_groups = defaultdict(list)
    for file_path in files:
        size = file_path.stat().st_size
        size_groups[size].append(file_path)
    
    # æª¢æŸ¥ç›¸åŒå¤§å°çš„æª”æ¡ˆ
    duplicate_groups = []
    for size, file_list in size_groups.items():
        if len(file_list) > 1:
            duplicate_groups.append((size, file_list))
    
    print(f"ç™¼ç¾ {len(duplicate_groups)} çµ„ç›¸åŒå¤§å°çš„æª”æ¡ˆ")
    print()
    
    # æª¢æŸ¥å…§å®¹é‡è¤‡
    content_hashes = defaultdict(list)
    total_duplicates = 0
    
    for size, file_list in duplicate_groups:
        print(f"æª”æ¡ˆå¤§å°: {size} bytes ({len(file_list)} å€‹æª”æ¡ˆ)")
        
        for file_path in file_list:
            # å…ˆå˜—è©¦è®€å– Excel å…§å®¹
            content_hash = get_excel_content_hash(file_path)
            if content_hash:
                content_hashes[content_hash].append(file_path)
            else:
                # å¦‚æœç„¡æ³•è®€å– Excelï¼Œä½¿ç”¨æª”æ¡ˆé›œæ¹Š
                file_hash = get_file_hash(file_path)
                if file_hash:
                    content_hashes[file_hash].append(file_path)
        
        # é¡¯ç¤ºé€™çµ„ä¸­çš„é‡è¤‡æƒ…æ³
        for content_hash, hash_files in content_hashes.items():
            if len(hash_files) > 1:
                print(f"  å…§å®¹é›œæ¹Š {content_hash[:8]}... é‡è¤‡ {len(hash_files)} æ¬¡:")
                for f in hash_files:
                    print(f"    - {f.name}")
                total_duplicates += len(hash_files) - 1
        
        print()
        content_hashes.clear()  # æ¸…ç©ºï¼Œæº–å‚™æª¢æŸ¥ä¸‹ä¸€çµ„
    
    print(f"ç¸½å…±ç™¼ç¾ {total_duplicates} å€‹å…§å®¹é‡è¤‡çš„æª”æ¡ˆ")
    
    # å»ºè­°æ¸…ç†
    print("\nå»ºè­°æ¸…ç†ç­–ç•¥ï¼š")
    print("1. ä¿ç•™åŸå§‹æª”æ¡ˆï¼ˆæ²’æœ‰æ™‚é–“æˆ³çš„ï¼‰")
    print("2. åˆªé™¤å¸¶æ™‚é–“æˆ³çš„å‚™ä»½æª”æ¡ˆ")
    print("3. æª¢æŸ¥æ˜¯å¦æœ‰å…¶ä»–å…§å®¹ä¸åŒçš„é‡è¤‡æª”æ¡ˆ")

if __name__ == "__main__":
    backup_dir = "data_raw/etmall/backup"
    if os.path.exists(backup_dir):
        check_duplicates(backup_dir)
    else:
        print(f"ç›®éŒ„ {backup_dir} ä¸å­˜åœ¨")
