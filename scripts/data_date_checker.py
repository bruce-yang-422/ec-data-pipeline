"""
===============================================================================
è³‡æ–™æ—¥æœŸå®Œæ•´æ€§æª¢æŸ¥å·¥å…· (Data Date Integrity Checker)
===============================================================================

ğŸ“‹ è…³æœ¬ç”¨é€”ï¼š
    æœ¬è…³æœ¬ç”¨æ–¼æª¢æŸ¥é›»å•†è¨‚å–®è³‡æ–™ä¸­çš„æ—¥æœŸæ¬„ä½å®Œæ•´æ€§ï¼Œç¢ºä¿è³‡æ–™å“è³ªå’Œé€£çºŒæ€§ã€‚
    ä¸»è¦é‡å° order_date æ¬„ä½é€²è¡Œé©—è­‰ï¼Œè­˜åˆ¥ç„¡æ•ˆæ—¥æœŸã€ç¼ºå¤±æ—¥æœŸç­‰è³‡æ–™å“è³ªå•é¡Œã€‚

ğŸ¯ æ ¸å¿ƒé‡é»ï¼š
    1. å¤šæ ¼å¼æ—¥æœŸè§£æï¼šæ”¯æ´å¤šç¨®æ—¥æœŸæ ¼å¼çš„è‡ªå‹•è­˜åˆ¥å’Œè§£æ
    2. æ—¥æœŸå®Œæ•´æ€§æª¢æŸ¥ï¼šæª¢æ¸¬æ—¥æœŸç¯„åœå…§çš„ç¼ºå¤±æ—¥æœŸ
    3. è³‡æ–™å“è³ªå ±å‘Šï¼šç”Ÿæˆè©³ç´°çš„æª¢æŸ¥å ±å‘Šï¼ŒåŒ…å«çµ±è¨ˆè³‡è¨Šå’Œå•é¡Œæ‘˜è¦
    4. æ™ºèƒ½ç¼ºå¤±æ—¥æœŸæ ¼å¼åŒ–ï¼šå°‡é€£çºŒçš„ç¼ºå¤±æ—¥æœŸåˆä½µç‚ºå€é–“é¡¯ç¤º

ğŸ”§ ä¸»è¦åŠŸèƒ½ï¼š
    - è‡ªå‹•æƒæ data_processed/merged ç›®éŒ„ä¸‹çš„æ‰€æœ‰ CSV æª”æ¡ˆ
    - è§£æå’Œé©—è­‰ order_date æ¬„ä½çš„æ—¥æœŸè³‡æ–™
    - è¨ˆç®—æ—¥æœŸç¯„åœå’Œè­˜åˆ¥ç¼ºå¤±æ—¥æœŸ
    - ç”Ÿæˆè©³ç´°çš„æª¢æŸ¥å ±å‘Šï¼ˆTXT æ ¼å¼ï¼‰
    - è¨˜éŒ„æ“ä½œæ—¥èªŒï¼Œä¾¿æ–¼è¿½è¹¤å’Œé™¤éŒ¯

ğŸ“Š è¼¸å‡ºçµæœï¼š
    - æ§åˆ¶å°å³æ™‚é¡¯ç¤ºæª¢æŸ¥é€²åº¦å’Œçµæœæ‘˜è¦
    - ç”Ÿæˆè©³ç´°çš„æª¢æŸ¥å ±å‘Šæª”æ¡ˆï¼ˆtemp/date_check_report_YYYYMMDD_HHMMSS.txtï¼‰
    - è¨˜éŒ„æ“ä½œæ—¥èªŒï¼ˆlogs/data_date_checker.logï¼‰

ğŸš€ ä½¿ç”¨å ´æ™¯ï¼š
    - é›»å•†è³‡æ–™å“è³ªæª¢æŸ¥
    - è¨‚å–®è³‡æ–™å®Œæ•´æ€§é©—è­‰
    - è³‡æ–™å€‰å„²è³‡æ–™å“è³ªç›£æ§
    - å ±è¡¨ç”Ÿæˆå‰çš„è³‡æ–™é©—è­‰

ğŸ“ è¼¸å…¥æª”æ¡ˆï¼š
    - ä½ç½®ï¼šdata_processed/merged/*.csv
    - è¦æ±‚ï¼šå¿…é ˆåŒ…å« order_date æ¬„ä½
    - æ ¼å¼ï¼šæ”¯æ´å¤šç¨®æ—¥æœŸæ ¼å¼ï¼ˆYYYY-MM-DD, YYYY/MM/DD, YYYYMMDD ç­‰ï¼‰

ğŸ“ˆ æª¢æŸ¥é …ç›®ï¼š
    - æ—¥æœŸæ¬„ä½å­˜åœ¨æ€§æª¢æŸ¥
    - æ—¥æœŸæ ¼å¼æœ‰æ•ˆæ€§é©—è­‰
    - æ—¥æœŸç¯„åœè¨ˆç®—
    - ç¼ºå¤±æ—¥æœŸè­˜åˆ¥å’Œçµ±è¨ˆ
    - è³‡æ–™å“è³ªæŒ‡æ¨™è¨ˆç®—

ä½œè€…ï¼šEC Data Pipeline åœ˜éšŠ
ç‰ˆæœ¬ï¼šv1.0.0
æ›´æ–°æ—¥æœŸï¼š2025-08-19
===============================================================================
"""

import os
import pandas as pd
import glob
from datetime import datetime, timedelta
from pathlib import Path
import json

# è·¯å¾‘è¨­å®š
PROJECT_ROOT = Path(__file__).parent.parent
DATA_PROCESSED_DIR = PROJECT_ROOT / 'data_processed' / 'merged'
OUTPUT_DIR = PROJECT_ROOT / 'temp'
LOG_DIR = PROJECT_ROOT / 'logs'

# ç¢ºä¿ç›®éŒ„å­˜åœ¨
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(LOG_DIR, exist_ok=True)

def find_data_files():
    """å°‹æ‰¾ data_processed/merged ä¸‹çš„æ‰€æœ‰ CSV æª”æ¡ˆ"""
    pattern = DATA_PROCESSED_DIR / '*.csv'
    files = glob.glob(str(pattern))
    
    if not files:
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° CSV æª”æ¡ˆæ–¼ {DATA_PROCESSED_DIR}")
    
    print(f"ğŸ“ æ‰¾åˆ° {len(files)} å€‹ CSV æª”æ¡ˆï¼š")
    for f in files:
        print(f"   - {Path(f).name}")
    
    return files

def parse_order_date(date_str):
    """è§£æ order_date å­—ä¸²ï¼Œæ”¯æ´å¤šç¨®æ ¼å¼"""
    if pd.isna(date_str) or str(date_str).strip() == '':
        return None
    
    date_str = str(date_str).strip()
    
    # å˜—è©¦å¤šç¨®æ—¥æœŸæ ¼å¼
    date_formats = [
        '%Y-%m-%d',
        '%Y/%m/%d',
        '%Y-%m-%d %H:%M:%S',
        '%Y/%m/%d %H:%M:%S',
        '%Y-%m-%d %H:%M',
        '%Y/%m/%d %H:%M',
        '%d/%m/%Y',
        '%m/%d/%Y',
        '%Y%m%d'
    ]
    
    for fmt in date_formats:
        try:
            parsed_date = pd.to_datetime(date_str, format=fmt)
            # åªè¿”å›æ—¥æœŸéƒ¨åˆ†ï¼Œå»é™¤æ™‚é–“
            return parsed_date.normalize()
        except:
            continue
    
    # å¦‚æœæ‰€æœ‰æ ¼å¼éƒ½å¤±æ•—ï¼Œå˜—è©¦ pandas è‡ªå‹•è§£æ
    try:
        parsed_date = pd.to_datetime(date_str)
        # åªè¿”å›æ—¥æœŸéƒ¨åˆ†ï¼Œå»é™¤æ™‚é–“
        return parsed_date.normalize()
    except:
        return None

def check_file_dates(file_path):
    """æª¢æŸ¥å–®ä¸€æª”æ¡ˆçš„æ—¥æœŸè³‡æ–™"""
    print(f"\nğŸ“– æª¢æŸ¥æª”æ¡ˆï¼š{Path(file_path).name}")
    
    try:
        # è®€å– CSV æª”æ¡ˆ
        df = pd.read_csv(file_path, dtype=str)
        print(f"ğŸ“Š ç¸½è³‡æ–™ç­†æ•¸ï¼š{len(df)}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ order_date æ¬„ä½
        if 'order_date' not in df.columns:
            print(f"âŒ æª”æ¡ˆä¸­æ²’æœ‰ order_date æ¬„ä½")
            return {
                'file_name': Path(file_path).name,
                'total_records': len(df),
                'has_order_date': False,
                'valid_dates': 0,
                'invalid_dates': 0,
                'date_range': None,
                'missing_dates': []
            }
        
        # è§£ææ—¥æœŸ
        valid_dates = []
        invalid_count = 0
        
        for idx, row in df.iterrows():
            date_obj = parse_order_date(row['order_date'])
            if date_obj is not None:
                valid_dates.append(date_obj)
            else:
                invalid_count += 1
        
        print(f"âœ… æœ‰æ•ˆæ—¥æœŸï¼š{len(valid_dates)} ç­†")
        print(f"âŒ ç„¡æ•ˆæ—¥æœŸï¼š{invalid_count} ç­†")
        
        if not valid_dates:
            print(f"âš ï¸ æ²’æœ‰æœ‰æ•ˆçš„æ—¥æœŸè³‡æ–™")
            return {
                'file_name': Path(file_path).name,
                'total_records': len(df),
                'has_order_date': True,
                'valid_dates': 0,
                'invalid_dates': invalid_count,
                'date_range': None,
                'missing_dates': []
            }
        
        # è¨ˆç®—æ—¥æœŸç¯„åœ
        min_date = min(valid_dates)
        max_date = max(valid_dates)
        date_range = (min_date, max_date)
        
        print(f"ğŸ“… æ—¥æœŸç¯„åœï¼š{min_date.strftime('%Y-%m-%d')} åˆ° {max_date.strftime('%Y-%m-%d')}")
        
        # æ‰¾å‡ºç¼ºå¤±çš„æ—¥æœŸ
        missing_dates = []
        current_date = min_date
        while current_date <= max_date:
            if current_date not in valid_dates:
                missing_dates.append(current_date.strftime('%Y-%m-%d'))
            current_date += timedelta(days=1)
        
        print(f"ğŸ” ç¼ºå¤±æ—¥æœŸï¼š{len(missing_dates)} å¤©")
        if missing_dates:
            print(f"   å‰5å€‹ç¼ºå¤±æ—¥æœŸï¼š{missing_dates[:5]}")
        
        return {
            'file_name': Path(file_path).name,
            'total_records': len(df),
            'has_order_date': True,
            'valid_dates': len(valid_dates),
            'invalid_dates': invalid_count,
            'date_range': date_range,
            'missing_dates': missing_dates
        }
        
    except Exception as e:
        print(f"âŒ è™•ç†æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return {
            'file_name': Path(file_path).name,
            'error': str(e)
        }

def generate_report(results):
    """ç”Ÿæˆå ±è¡¨"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    report_file = OUTPUT_DIR / f'date_check_report_{timestamp}.txt'
    
    def format_missing_dates(missing_dates):
        """å°‡ç¼ºå¤±æ—¥æœŸæ ¼å¼åŒ–ç‚ºå€é–“é¡¯ç¤º"""
        if not missing_dates:
            return []
        
        # å°‡å­—ä¸²æ—¥æœŸè½‰æ›ç‚º datetime ç‰©ä»¶
        date_objects = [datetime.strptime(date, '%Y-%m-%d') for date in missing_dates]
        date_objects.sort()
        
        ranges = []
        start_date = end_date = date_objects[0]
        
        for i in range(1, len(date_objects)):
            current_date = date_objects[i]
            # å¦‚æœç•¶å‰æ—¥æœŸèˆ‡å‰ä¸€å€‹æ—¥æœŸé€£çºŒ
            if (current_date - end_date).days == 1:
                end_date = current_date
            else:
                # ä¸é€£çºŒï¼Œä¿å­˜ç•¶å‰å€é–“
                if start_date == end_date:
                    ranges.append(start_date.strftime('%Y-%m-%d'))
                else:
                    ranges.append(f"{start_date.strftime('%Y-%m-%d')}~{end_date.strftime('%Y-%m-%d')}")
                start_date = end_date = current_date
        
        # è™•ç†æœ€å¾Œä¸€å€‹å€é–“
        if start_date == end_date:
            ranges.append(start_date.strftime('%Y-%m-%d'))
        else:
            ranges.append(f"{start_date.strftime('%Y-%m-%d')}~{end_date.strftime('%Y-%m-%d')}")
        
        return ranges
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("è³‡æ–™æ—¥æœŸæª¢æŸ¥å ±è¡¨\n")
        f.write("=" * 80 + "\n")
        f.write(f"ç”Ÿæˆæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æª¢æŸ¥æª”æ¡ˆæ•¸ï¼š{len(results)}\n\n")
        
        # ç¸½é«”çµ±è¨ˆ
        total_files = len(results)
        files_with_order_date = sum(1 for r in results if r.get('has_order_date', False))
        total_records = sum(r.get('total_records', 0) for r in results if 'total_records' in r)
        total_valid_dates = sum(r.get('valid_dates', 0) for r in results if 'valid_dates' in r)
        total_invalid_dates = sum(r.get('invalid_dates', 0) for r in results if 'invalid_dates' in r)
        
        f.write("ğŸ“Š ç¸½é«”çµ±è¨ˆ\n")
        f.write("-" * 40 + "\n")
        f.write(f"æª¢æŸ¥æª”æ¡ˆæ•¸ï¼š{total_files}\n")
        f.write(f"åŒ…å« order_date æ¬„ä½çš„æª”æ¡ˆï¼š{files_with_order_date}\n")
        f.write(f"ç¸½è³‡æ–™ç­†æ•¸ï¼š{total_records:,}\n")
        f.write(f"æœ‰æ•ˆæ—¥æœŸç­†æ•¸ï¼š{total_valid_dates:,}\n")
        f.write(f"ç„¡æ•ˆæ—¥æœŸç­†æ•¸ï¼š{total_invalid_dates:,}\n")
        f.write(f"æ—¥æœŸæœ‰æ•ˆç‡ï¼š{total_valid_dates/(total_valid_dates+total_invalid_dates)*100:.1f}%\n\n")
        
        # å„æª”æ¡ˆè©³ç´°è³‡è¨Š
        f.write("ğŸ“ å„æª”æ¡ˆè©³ç´°è³‡è¨Š\n")
        f.write("=" * 80 + "\n")
        
        for result in results:
            f.write(f"\næª”æ¡ˆåç¨±ï¼š{result['file_name']}\n")
            f.write("-" * 50 + "\n")
            
            if 'error' in result:
                f.write(f"âŒ éŒ¯èª¤ï¼š{result['error']}\n")
                continue
            
            f.write(f"ç¸½è³‡æ–™ç­†æ•¸ï¼š{result['total_records']:,}\n")
            
            if not result.get('has_order_date', False):
                f.write("âŒ æ²’æœ‰ order_date æ¬„ä½\n")
                continue
            
            f.write(f"æœ‰æ•ˆæ—¥æœŸï¼š{result['valid_dates']:,} ç­†\n")
            f.write(f"ç„¡æ•ˆæ—¥æœŸï¼š{result['invalid_dates']:,} ç­†\n")
            
            if result['date_range']:
                min_date, max_date = result['date_range']
                f.write(f"æ—¥æœŸç¯„åœï¼š{min_date.strftime('%Y-%m-%d')} åˆ° {max_date.strftime('%Y-%m-%d')}\n")
                f.write(f"ç¼ºå¤±æ—¥æœŸæ•¸ï¼š{len(result['missing_dates'])} å¤©\n")
                
                if result['missing_dates']:
                    f.write("ç¼ºå¤±æ—¥æœŸåˆ—è¡¨ï¼š\n")
                    # æ ¼å¼åŒ–ç‚ºå€é–“é¡¯ç¤º
                    formatted_ranges = format_missing_dates(result['missing_dates'])
                    
                    if len(formatted_ranges) <= 20:
                        # å¦‚æœå€é–“ä¸å¤šï¼Œå…¨éƒ¨é¡¯ç¤º
                        for date_range in formatted_ranges:
                            f.write(f"  - {date_range}\n")
                    else:
                        # å¦‚æœå€é–“å¾ˆå¤šï¼Œé¡¯ç¤ºå‰10å€‹å’Œå¾Œ10å€‹
                        f.write("  (é¡¯ç¤ºå‰10å€‹å’Œå¾Œ10å€‹)\n")
                        for date_range in formatted_ranges[:10]:
                            f.write(f"  - {date_range}\n")
                        f.write("  ...\n")
                        for date_range in formatted_ranges[-10:]:
                            f.write(f"  - {date_range}\n")
                        f.write(f"  (å…± {len(formatted_ranges)} å€‹å€é–“)\n")
                else:
                    f.write("âœ… æ²’æœ‰ç¼ºå¤±æ—¥æœŸ\n")
        
        # ç¼ºå¤±æ—¥æœŸæ‘˜è¦
        f.write("\n\nğŸ” ç¼ºå¤±æ—¥æœŸæ‘˜è¦\n")
        f.write("=" * 80 + "\n")
        
        all_missing_dates = []
        for result in results:
            if 'missing_dates' in result and result['missing_dates']:
                all_missing_dates.extend(result['missing_dates'])
        
        if all_missing_dates:
            # å»é‡ä¸¦æ’åº
            unique_missing_dates = sorted(list(set(all_missing_dates)))
            f.write(f"ç¸½å…±æœ‰ {len(unique_missing_dates)} å€‹ä¸åŒçš„ç¼ºå¤±æ—¥æœŸï¼š\n")
            
            # æ ¼å¼åŒ–ç‚ºå€é–“é¡¯ç¤º
            formatted_ranges = format_missing_dates(unique_missing_dates)
            
            if len(formatted_ranges) <= 50:
                for date_range in formatted_ranges:
                    f.write(f"  - {date_range}\n")
            else:
                f.write("  (é¡¯ç¤ºå‰25å€‹å’Œå¾Œ25å€‹)\n")
                for date_range in formatted_ranges[:25]:
                    f.write(f"  - {date_range}\n")
                f.write("  ...\n")
                for date_range in formatted_ranges[-25:]:
                    f.write(f"  - {date_range}\n")
                f.write(f"  (å…± {len(formatted_ranges)} å€‹å€é–“)\n")
        else:
            f.write("âœ… æ‰€æœ‰æª”æ¡ˆéƒ½æ²’æœ‰ç¼ºå¤±æ—¥æœŸ\n")
    
    print(f"ğŸ“„ å ±è¡¨å·²ç”Ÿæˆï¼š{report_file}")
    return report_file

def main():
    """ä¸»è¦è™•ç†å‡½æ•¸"""
    try:
        print("ğŸš€ é–‹å§‹æª¢æŸ¥è³‡æ–™æ—¥æœŸ...")
        
        # å°‹æ‰¾æª”æ¡ˆ
        data_files = find_data_files()
        
        # æª¢æŸ¥æ¯å€‹æª”æ¡ˆ
        results = []
        for file_path in data_files:
            result = check_file_dates(file_path)
            results.append(result)
        
        # ç”Ÿæˆå ±è¡¨
        report_file = generate_report(results)
        
        print(f"\nğŸ‰ æª¢æŸ¥å®Œæˆï¼")
        print(f"ğŸ“ æª¢æŸ¥æª”æ¡ˆæ•¸ï¼š{len(results)}")
        print(f"ğŸ“„ å ±è¡¨ä½ç½®ï¼š{report_file}")
        
        # å¯«å…¥ log
        log_file = LOG_DIR / 'data_date_checker.log'
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(f"{datetime.now().isoformat()} - æª¢æŸ¥å®Œæˆ\n")
            f.write(f"  æª¢æŸ¥æª”æ¡ˆæ•¸ï¼š{len(results)}, å ±è¡¨ï¼š{report_file.name}\n")
        
        print(f"ğŸ“ è©³ç´°è¨˜éŒ„å·²å¯«å…¥ï¼š{log_file}")
        
    except Exception as e:
        print(f"âŒ éŒ¯èª¤ï¼š{e}")
        # å¯«å…¥éŒ¯èª¤ log
        log_file = LOG_DIR / 'data_date_checker.log'
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(f"{datetime.now().isoformat()} - éŒ¯èª¤ï¼š{e}\n")

if __name__ == '__main__':
    main() 