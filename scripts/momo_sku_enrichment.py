"""
===============================================================================
MOMO SKU è³‡æ–™è±å¯ŒåŒ–å·¥å…· (MOMO SKU Data Enrichment Tool)
===============================================================================

ğŸ“‹ è…³æœ¬ç”¨é€”ï¼š
    æœ¬è…³æœ¬ç”¨æ–¼ç‚º MOMO è³¼ç‰©ä¸­å¿ƒçš„è¨‚å–®è³‡æ–™å¢åŠ å•†å“ç›¸é—œè³‡è¨Šï¼Œé€éæ¢ç¢¼å°æ‡‰è¡¨
    è‡ªå‹•å¡«å…¥å•†å“åˆ†é¡ã€å“ç‰Œã€è¦æ ¼ç­‰è©³ç´°è³‡è¨Šï¼Œæå‡è³‡æ–™å®Œæ•´æ€§å’Œåˆ†æåƒ¹å€¼ã€‚

ğŸ¯ æ ¸å¿ƒé‡é»ï¼š
    1. æ™ºèƒ½æ¢ç¢¼åŒ¹é…ï¼šæ”¯æ´å¤šå€‹æ¢ç¢¼æ¬„ä½çš„è‡ªå‹•è­˜åˆ¥å’ŒåŒ¹é…
    2. å•†å“è³‡è¨Šè±å¯Œï¼šè‡ªå‹•å¡«å…¥ 18 å€‹å•†å“ç›¸é—œæ¬„ä½
    3. é«˜åŒ¹é…ç‡ï¼šé€éæ¢ç¢¼å°æ‡‰è¡¨å¯¦ç¾ç²¾ç¢ºçš„å•†å“è³‡è¨ŠåŒ¹é…
    4. æ‰¹æ¬¡è™•ç†ï¼šæ”¯æ´å¤šå€‹ MOMO CSV æª”æ¡ˆçš„æ‰¹æ¬¡è™•ç†

ğŸ”§ ä¸»è¦åŠŸèƒ½ï¼š
    - è¼‰å…¥ SKU mapping é…ç½®æª”æ¡ˆï¼ˆconfig/sku_mapping.jsonï¼‰
    - è‡ªå‹•æƒæ data_processed/merged ç›®éŒ„ä¸‹çš„ MOMO CSV æª”æ¡ˆ
    - é€éæ¢ç¢¼æ¬„ä½åŒ¹é…å•†å“ä¸»æª”è³‡è¨Š
    - è‡ªå‹•å¡«å…¥å•†å“åˆ†é¡ã€å“ç‰Œã€è¦æ ¼ç­‰è©³ç´°è³‡è¨Š
    - ç”Ÿæˆè±å¯ŒåŒ–å¾Œçš„ CSV æª”æ¡ˆï¼ˆæª”åå¾Œç¶´ _enrichedï¼‰
    - æä¾›è©³ç´°çš„åŒ¹é…çµ±è¨ˆå’Œè™•ç†å ±å‘Š

ğŸ“Š è³‡æ–™è±å¯ŒåŒ–æ¬„ä½ï¼š
    å•†å“åˆ†é¡ï¼šcategory, subcategory
    å“ç‰Œè³‡è¨Šï¼šbrand, series
    å•†å“å±¬æ€§ï¼špet_type, product_name_mapped, item_code, sku
    å•†å“æ¨™ç±¤ï¼štags, spec, unit, package_type, package_qty
    ä¾›æ‡‰å•†è³‡è¨Šï¼šorigin, cost, supplier_code, supplier, supplier_ref

ğŸ” æ¢ç¢¼åŒ¹é…é‚è¼¯ï¼š
    1. å„ªå…ˆæª¢æŸ¥ product_manufacturer_code æ¬„ä½
    2. å…¶æ¬¡æª¢æŸ¥ barcode æ¬„ä½
    3. æœ€å¾Œæª¢æŸ¥ product_sku_main æ¬„ä½
    4. ä»»ä¸€æ¬„ä½åŒ¹é…æˆåŠŸå³å¡«å…¥å°æ‡‰å•†å“è³‡è¨Š

ğŸš€ ä½¿ç”¨å ´æ™¯ï¼š
    - MOMO è¨‚å–®è³‡æ–™å“è³ªæå‡
    - å•†å“è³‡è¨Šè‡ªå‹•åŒ–è±å¯Œ
    - é›»å•†è³‡æ–™åˆ†ææº–å‚™
    - å•†å“ä¸»æª”è³‡æ–™æ•´åˆ

ğŸ“ è¼¸å…¥æª”æ¡ˆï¼š
    - ä½ç½®ï¼šdata_processed/merged/momo_*.csv
    - è¦æ±‚ï¼šå¿…é ˆåŒ…å«æ¢ç¢¼ç›¸é—œæ¬„ä½
    - é…ç½®ï¼šconfig/sku_mapping.jsonï¼ˆæ¢ç¢¼å°æ‡‰è¡¨ï¼‰

ğŸ“ˆ è¼¸å‡ºçµæœï¼š
    - è±å¯ŒåŒ–å¾Œçš„ CSV æª”æ¡ˆï¼ˆæª”åå¾Œç¶´ _enrichedï¼‰
    - æ§åˆ¶å°å³æ™‚é¡¯ç¤ºè™•ç†é€²åº¦å’ŒåŒ¹é…çµ±è¨ˆ
    - è©³ç´°çš„æ“ä½œæ—¥èªŒï¼ˆlogs/momo_sku_enrichment.logï¼‰
    - æ•´é«”åŒ¹é…ç‡å’Œè™•ç†çµ±è¨ˆæ‘˜è¦

âš™ï¸ é…ç½®è¦æ±‚ï¼š
    - sku_mapping.json å¿…é ˆåŒ…å« barcode_mapping çµæ§‹
    - æ¯å€‹æ¢ç¢¼å°æ‡‰å®Œæ•´çš„å•†å“è³‡è¨Šå­—å…¸
    - æ”¯æ´çš„æ¬„ä½ï¼šcategory, subcategory, brand, series, pet_type ç­‰

ä½œè€…ï¼šEC Data Pipeline åœ˜éšŠ
ç‰ˆæœ¬ï¼šv1.0.0
æ›´æ–°æ—¥æœŸï¼š2025-08-19
===============================================================================
"""

import os
import pandas as pd
import json
import glob
from datetime import datetime
from pathlib import Path

# è·¯å¾‘è¨­å®š
PROJECT_ROOT = Path(__file__).parent.parent
DATA_PROCESSED_DIR = PROJECT_ROOT / 'data_processed' / 'merged'
CONFIG_DIR = PROJECT_ROOT / 'config'
LOG_DIR = PROJECT_ROOT / 'logs'

# ç¢ºä¿ç›®éŒ„å­˜åœ¨
os.makedirs(LOG_DIR, exist_ok=True)

def load_sku_mapping():
    """è¼‰å…¥ SKU mapping è³‡æ–™"""
    mapping_file = CONFIG_DIR / 'sku_mapping.json'
    
    if not mapping_file.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° SKU mapping æª”æ¡ˆï¼š{mapping_file}")
    
    with open(mapping_file, 'r', encoding='utf-8') as f:
        mapping_data = json.load(f)
    
    print(f"âœ… æˆåŠŸè¼‰å…¥ SKU mappingï¼ŒåŒ…å« {len(mapping_data['barcode_mapping'])} ç­†æ¢ç¢¼è³‡æ–™")
    return mapping_data

def find_momo_files():
    """å°‹æ‰¾ momo CSV æª”æ¡ˆ"""
    pattern = DATA_PROCESSED_DIR / 'momo_*.csv'
    files = glob.glob(str(pattern))
    
    # æ’é™¤å·²ç¶“è™•ç†éçš„ _enriched.csv æª”æ¡ˆ
    files = [f for f in files if not Path(f).name.endswith('_enriched.csv')]
    
    if not files:
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° momo CSV æª”æ¡ˆæ–¼ {DATA_PROCESSED_DIR}")
    
    print(f"ğŸ“ æ‰¾åˆ° {len(files)} å€‹ momo CSV æª”æ¡ˆï¼š")
    for f in files:
        print(f"   - {Path(f).name}")
    
    return files

def get_barcode_from_row(row, mapping_data):
    """å¾è³‡æ–™è¡Œä¸­å–å¾—æ¢ç¢¼ï¼Œä¸¦å›å‚³å°æ‡‰çš„å•†å“è³‡è¨Š"""
    # å˜—è©¦ä¸åŒçš„æ¢ç¢¼æ¬„ä½
    barcode_fields = ['product_manufacturer_code', 'barcode', 'product_sku_main']
    
    for field in barcode_fields:
        if field in row and pd.notna(row[field]) and str(row[field]).strip() != '':
            barcode = str(row[field]).strip()
            
            # åœ¨ mapping ä¸­å°‹æ‰¾å°æ‡‰çš„å•†å“è³‡è¨Š
            if barcode in mapping_data['barcode_mapping']:
                return mapping_data['barcode_mapping'][barcode]
    
    return None

def enrich_momo_data(file_path, mapping_data):
    """ç‚º momo è³‡æ–™å¢åŠ æ¬„ä½"""
    print(f"\nğŸ“– è™•ç†æª”æ¡ˆï¼š{Path(file_path).name}")
    
    # è®€å– CSV æª”æ¡ˆ
    df = pd.read_csv(file_path, dtype=str)
    print(f"ğŸ“Š åŸå§‹è³‡æ–™ç­†æ•¸ï¼š{len(df)}")
    
    # è¦å¢åŠ çš„æ¬„ä½ï¼ˆç§»é™¤æŒ‡å®šçš„æ¬„ä½ï¼‰
    new_columns = [
        'category', 'subcategory', 'brand', 'series', 'pet_type', 
        'product_name_mapped', 'item_code', 'sku', 'tags', 'spec', 
        'unit', 'package_type', 'package_qty', 'origin', 'cost', 
        'supplier_code', 'supplier', 'supplier_ref'
    ]
    
    # åˆå§‹åŒ–æ–°æ¬„ä½
    for col in new_columns:
        df[col] = ''
    
    # çµ±è¨ˆè³‡è¨Š
    matched_count = 0
    unmatched_count = 0
    
    # é€è¡Œè™•ç†
    for idx, row in df.iterrows():
        product_info = get_barcode_from_row(row, mapping_data)
        
        if product_info:
            matched_count += 1
            # å¡«å…¥å°æ‡‰çš„å•†å“è³‡è¨Š
            for col in new_columns:
                if col in product_info and product_info[col] is not None:
                    df.at[idx, col] = str(product_info[col])
        else:
            unmatched_count += 1
    
    print(f"âœ… åŒ¹é…æˆåŠŸï¼š{matched_count} ç­†")
    print(f"âŒ æœªåŒ¹é…ï¼š{unmatched_count} ç­†")
    print(f"ğŸ“ˆ åŒ¹é…ç‡ï¼š{matched_count/(matched_count+unmatched_count)*100:.1f}%")
    
    return df

def save_enriched_data(df, original_file_path):
    """å„²å­˜å¢åŠ æ¬„ä½å¾Œçš„è³‡æ–™"""
    # å»ºç«‹æ–°çš„æª”æ¡ˆåç¨±
    original_path = Path(original_file_path)
    new_filename = f"{original_path.stem}_enriched{original_path.suffix}"
    output_path = original_path.parent / new_filename
    
    # å„²å­˜æª”æ¡ˆ
    df.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"ğŸ’¾ å·²å„²å­˜ï¼š{output_path.name}")
    
    return output_path

def main():
    """ä¸»è¦è™•ç†å‡½æ•¸"""
    try:
        print("ğŸš€ é–‹å§‹è™•ç† momo è³‡æ–™å¢åŠ æ¬„ä½...")
        
        # è¼‰å…¥ SKU mapping
        mapping_data = load_sku_mapping()
        
        # å°‹æ‰¾ momo æª”æ¡ˆ
        momo_files = find_momo_files()
        
        # è™•ç†æ¯å€‹æª”æ¡ˆ
        processed_files = []
        total_matched = 0
        total_unmatched = 0
        
        for file_path in momo_files:
            try:
                # å¢åŠ æ¬„ä½
                enriched_df = enrich_momo_data(file_path, mapping_data)
                
                # å„²å­˜çµæœ
                output_path = save_enriched_data(enriched_df, file_path)
                processed_files.append(output_path)
                
                # çµ±è¨ˆåŒ¹é…æ•¸é‡
                matched_count = len(enriched_df[enriched_df['sku'] != ''])
                unmatched_count = len(enriched_df[enriched_df['sku'] == ''])
                total_matched += matched_count
                total_unmatched += unmatched_count
                
            except Exception as e:
                print(f"âŒ è™•ç†æª”æ¡ˆ {Path(file_path).name} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                continue
        
        # è¼¸å‡ºç¸½çµ
        print(f"\nğŸ‰ è™•ç†å®Œæˆï¼")
        print(f"ğŸ“ è™•ç†æª”æ¡ˆæ•¸ï¼š{len(processed_files)}")
        print(f"ğŸ“Š ç¸½åŒ¹é…ç­†æ•¸ï¼š{total_matched}")
        print(f"ğŸ“Š ç¸½æœªåŒ¹é…ç­†æ•¸ï¼š{total_unmatched}")
        print(f"ğŸ“ˆ æ•´é«”åŒ¹é…ç‡ï¼š{total_matched/(total_matched+total_unmatched)*100:.1f}%")
        
        # å¯«å…¥ log
        log_file = LOG_DIR / 'momo_sku_enrichment.log'
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(f"{datetime.now().isoformat()} - è™•ç†å®Œæˆ\n")
            f.write(f"  è™•ç†æª”æ¡ˆæ•¸ï¼š{len(processed_files)}, ç¸½åŒ¹é…ï¼š{total_matched}, ç¸½æœªåŒ¹é…ï¼š{total_unmatched}\n")
        
        print(f"ğŸ“ è©³ç´°è¨˜éŒ„å·²å¯«å…¥ï¼š{log_file}")
        
    except Exception as e:
        print(f"âŒ éŒ¯èª¤ï¼š{e}")
        # å¯«å…¥éŒ¯èª¤ log
        log_file = LOG_DIR / 'momo_sku_enrichment.log'
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(f"{datetime.now().isoformat()} - éŒ¯èª¤ï¼š{e}\n")

if __name__ == '__main__':
    main() 