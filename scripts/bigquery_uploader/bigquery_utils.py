#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BigQuery å·¥å…·å‡½æ•¸æ¨¡çµ„

ä¸»è¦åŠŸèƒ½ï¼š
- BigQuery å®¢æˆ¶ç«¯å»ºç«‹èˆ‡èªè­‰
- CSV æª”æ¡ˆä¸Šå‚³è‡³ BigQuery
- é‡è¤‡è³‡æ–™æª¢æŸ¥èˆ‡è™•ç†
- è³‡æ–™è¡¨å­˜åœ¨æ€§æª¢æŸ¥
- è³‡æ–™è¡¨è³‡è¨ŠæŸ¥è©¢

Authors: æ¥Šç¿”å¿— & AI Collective
Studio: tranquility-base
"""

import os
import pandas as pd
from google.cloud import bigquery
from google.cloud.exceptions import NotFound
from typing import List, Optional, Dict, Any


def get_bq_client(credential_path: str) -> bigquery.Client:
    """å»ºç«‹ BigQuery å®¢æˆ¶ç«¯"""
    try:
        # è¨­å®šç’°å¢ƒè®Šæ•¸
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = credential_path
        
        # å»ºç«‹å®¢æˆ¶ç«¯
        client = bigquery.Client()
        
        print(f"âœ… BigQuery å®¢æˆ¶ç«¯å»ºç«‹æˆåŠŸ")
        return client
        
    except Exception as e:
        print(f"âŒ BigQuery å®¢æˆ¶ç«¯å»ºç«‹å¤±æ•—: {e}")
        raise


def upload_csv_to_bq(
    client: bigquery.Client,
    csv_path: str,
    dataset_id: str,
    table_id: str,
    schema: List[bigquery.SchemaField],
    write_disposition: str = "WRITE_APPEND",
    logger=None
) -> bool:
    """ä¸Šå‚³ CSV æª”æ¡ˆè‡³ BigQuery"""
    try:
        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if not os.path.exists(csv_path):
            error_msg = f"âŒ CSV æª”æ¡ˆä¸å­˜åœ¨: {csv_path}"
            if logger:
                logger.error(error_msg)
            else:
                print(error_msg)
            return False
            
        # æª¢æŸ¥æª”æ¡ˆå¤§å°
        file_size = os.path.getsize(csv_path)
        if file_size == 0:
            error_msg = f"âŒ CSV æª”æ¡ˆç‚ºç©º: {csv_path}"
            if logger:
                logger.error(error_msg)
            else:
                print(error_msg)
            return False
            
        size_msg = f"ğŸ“Š CSV æª”æ¡ˆå¤§å°: {file_size / 1024 / 1024:.2f} MB"
        if logger:
            logger.info(size_msg)
        else:
            print(size_msg)
        
        # å»ºç«‹ table åƒè€ƒ
        table_ref = client.dataset(dataset_id).table(table_id)
        
        # è¨­å®š job config
        job_config = bigquery.LoadJobConfig(
            schema=schema,
            write_disposition=write_disposition,
            source_format=bigquery.SourceFormat.CSV,
            skip_leading_rows=1,  # è·³éæ¨™é¡Œè¡Œ
            autodetect=False,  # ä½¿ç”¨è‡ªå®šç¾© schema
        )
        
        # åŸ·è¡Œä¸Šå‚³
        upload_msg = f"ğŸ“¤ é–‹å§‹ä¸Šå‚³è‡³ {dataset_id}.{table_id}..."
        if logger:
            logger.info(upload_msg)
        else:
            print(upload_msg)
        
        with open(csv_path, "rb") as source_file:
            job = client.load_table_from_file(
                source_file,
                table_ref,
                job_config=job_config
            )
            
        # ç­‰å¾…å®Œæˆ
        job.result()
        
        # æª¢æŸ¥çµæœ
        table = client.get_table(table_ref)
        success_msg = f"âœ… ä¸Šå‚³æˆåŠŸï¼è³‡æ–™è¡¨ {table_id} å…±æœ‰ {table.num_rows} ç­†è³‡æ–™"
        if logger:
            logger.info(success_msg)
        else:
            print(success_msg)
        
        return True
        
    except Exception as e:
        error_msg = f"âŒ ä¸Šå‚³å¤±æ•—: {e}"
        if logger:
            logger.error(error_msg)
        else:
            print(error_msg)
        return False


def check_duplicate_order_sn(df: pd.DataFrame) -> Optional[List[str]]:
    """æª¢æŸ¥ order_sn é‡è¤‡"""
    try:
        if 'order_sn' not in df.columns:
            print("âš ï¸ è³‡æ–™æ¡†ä¸­æ²’æœ‰ order_sn æ¬„ä½")
            return None
            
        # æ‰¾å‡ºé‡è¤‡çš„ order_sn
        duplicates = df[df['order_sn'].duplicated(keep=False)]
        
        if len(duplicates) > 0:
            duplicate_sns = duplicates['order_sn'].unique().tolist()
            print(f"âš ï¸ ç™¼ç¾ {len(duplicate_sns)} å€‹é‡è¤‡çš„ order_sn")
            return duplicate_sns
        else:
            print("âœ… ç„¡é‡è¤‡çš„ order_sn")
            return None
            
    except Exception as e:
        print(f"âŒ æª¢æŸ¥é‡è¤‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None


def check_table_exists(client: bigquery.Client, dataset_id: str, table_id: str) -> bool:
    """æª¢æŸ¥ BigQuery è³‡æ–™è¡¨æ˜¯å¦å­˜åœ¨"""
    try:
        table_ref = client.dataset(dataset_id).table(table_id)
        client.get_table(table_ref)
        return True
    except NotFound:
        return False


def get_table_info(client: bigquery.Client, dataset_id: str, table_id: str) -> Optional[Dict[str, Any]]:
    """å–å¾—è³‡æ–™è¡¨è³‡è¨Š"""
    try:
        table_ref = client.dataset(dataset_id).table(table_id)
        table = client.get_table(table_ref)
        
        return {
            'table_id': table.table_id,
            'dataset_id': table.dataset_id,
            'project': table.project,
            'num_rows': table.num_rows,
            'num_bytes': table.num_bytes,
            'created': table.created,
            'modified': table.modified,
            'schema': [field.name for field in table.schema]
        }
        
    except Exception as e:
        print(f"âŒ å–å¾—è³‡æ–™è¡¨è³‡è¨Šå¤±æ•—: {e}")
        return None
