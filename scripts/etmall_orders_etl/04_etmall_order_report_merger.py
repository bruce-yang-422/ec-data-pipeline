#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ±æ£®è³¼ç‰©è¨‚å–®å ±è¡¨åˆä½µè…³æœ¬
åˆä½µ temp/etmall/Order_Report ç›®éŒ„ä¸‹çš„æ‰€æœ‰ CSV æª”æ¡ˆ
è¼¸å‡ºåˆ° temp/etmall ç›®éŒ„
åˆä½µå®Œæˆå¾Œç§»é™¤ temp/etmall/Order_Report ç›®éŒ„åŠå…¶å…§å®¹
"""

import os
import pandas as pd
import glob
from pathlib import Path
import logging
from datetime import datetime
import shutil
import time

# è¨­å®šæ—¥èªŒ
def setup_logging():
    """è¨­å®šæ—¥èªŒé…ç½®"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = log_dir / f"etmall_order_report_merger_{timestamp}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

def find_csv_files(base_dir):
    """éè¿´æœå°‹æŒ‡å®šç›®éŒ„ä¸‹çš„æ‰€æœ‰ CSV æª”æ¡ˆ"""
    csv_files = []
    
    # æœå°‹æ‰€æœ‰å­ç›®éŒ„
    for root, dirs, files in os.walk(base_dir):
        for file in files:
            if file.lower().endswith('.csv'):
                csv_files.append(os.path.join(root, file))
    
    return sorted(csv_files)

def process_csv_file(file_path, logger):
    """è™•ç†å–®ä¸€ CSV æª”æ¡ˆ"""
    try:
        logger.info(f"æ­£åœ¨è™•ç†æª”æ¡ˆ: {file_path}")
        
        # è®€å– CSV æª”æ¡ˆï¼Œå¼·åˆ¶æ‰€æœ‰æ¬„ä½ç‚ºå­—ä¸²é¡å‹
        df = pd.read_csv(file_path, encoding='utf-8-sig', dtype=str)
        
        # å°‡ä¸­æ–‡æ¬„ä½è½‰æ›ç‚ºè‹±æ–‡æ¬„ä½
        df = convert_columns_to_english(df, logger)
        
        logger.info(f"æª”æ¡ˆ {file_path} è™•ç†å®Œæˆï¼Œå…± {len(df)} ç­†è³‡æ–™")
        logger.info(f"æ¬„ä½: {list(df.columns)}")
        
        return df
        
    except Exception as e:
        logger.error(f"è™•ç†æª”æ¡ˆ {file_path} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return None

def convert_columns_to_english(df, logger):
    """å°‡ä¸­æ–‡æ¬„ä½è½‰æ›ç‚ºè‹±æ–‡æ¬„ä½"""
    try:
        logger.info("æ­£åœ¨å°‡ä¸­æ–‡æ¬„ä½è½‰æ›ç‚ºè‹±æ–‡æ¬„ä½...")
        
        # å®šç¾©ä¸­è‹±æ–‡æ¬„ä½å°æ‡‰
        column_mapping = {
            'å¹³å°': 'platform',
            'è¨‚å–®æ—¥æœŸ': 'order_date',
            'è¨‚å–®ç·¨è™Ÿ': 'order_sn',
            'é …æ¬¡': 'item_no',
            'è¨‚å–®ID': 'order_line_uid',
            'è³£å®¶å•†å“ç·¨è™Ÿ': 'seller_product_sn',
            'å•†å“åç¨±': 'product_name_platform',
            'æ•¸é‡': 'quantity',
            'å–®åƒ¹': 'unit_price',
            'å®¢æˆ¶å§“å': 'customer_name',
            'å®¢æˆ¶é›»è©±': 'customer_phone',
            'é…é€åœ°å€': 'shipping_address',
            'å‚™è¨»': 'note',
            'å¹³å°æˆæœ¬': 'cost_to_platform',
            'é…é€å…¬å¸': 'delivery_company'
        }
        
        # é‡æ–°å‘½åæ¬„ä½
        df_renamed = df.rename(columns=column_mapping)
        
        # è¨˜éŒ„æ¬„ä½è½‰æ›
        converted_columns = []
        for chinese_col, english_col in column_mapping.items():
            if chinese_col in df.columns:
                converted_columns.append(f"{chinese_col} -> {english_col}")
        
        if converted_columns:
            logger.info("æ¬„ä½è½‰æ›å®Œæˆ:")
            for conversion in converted_columns:
                logger.info(f"  {conversion}")
        else:
            logger.info("æ²’æœ‰éœ€è¦è½‰æ›çš„ä¸­æ–‡æ¬„ä½")
        
        return df_renamed
        
    except Exception as e:
        logger.error(f"æ¬„ä½è½‰æ›æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return df

def merge_csv_files(csv_files, logger):
    """åˆä½µæ‰€æœ‰ CSV æª”æ¡ˆ"""
    all_dataframes = []
    total_rows = 0
    processed_files = 0
    
    for file_path in csv_files:
        df = process_csv_file(file_path, logger)
        if df is not None:
            all_dataframes.append(df)
            total_rows += len(df)
            processed_files += 1
    
    if not all_dataframes:
        logger.error("æ²’æœ‰æˆåŠŸè™•ç†ä»»ä½• CSV æª”æ¡ˆ")
        return None
    
    # åˆä½µæ‰€æœ‰è³‡æ–™æ¡†
    logger.info("æ­£åœ¨åˆä½µæ‰€æœ‰è³‡æ–™æ¡†...")
    merged_df = pd.concat(all_dataframes, ignore_index=True)
    
    # æ¸…ç†è¨˜æ†¶é«”ï¼Œç¢ºä¿æª”æ¡ˆå¥æŸ„è¢«é‡‹æ”¾
    del all_dataframes
    
    logger.info(f"åˆä½µå®Œæˆï¼ç¸½å…±è™•ç† {processed_files} å€‹æª”æ¡ˆï¼Œåˆè¨ˆ {total_rows} ç­†è³‡æ–™")
    
    # æ–°å¢ item_no æ¬„ä½ï¼šåŒä¸€å€‹ order_sn çµ¦äºˆæµæ°´è™Ÿ 1, 2, 3, ...
    logger.info("æ­£åœ¨æ–°å¢ item_no æ¬„ä½...")
    merged_df['item_no'] = merged_df.groupby('order_sn').cumcount() + 1
    
    # æ–°å¢ order_line_uid æ¬„ä½ï¼šorder_sn + "_" + item_no
    logger.info("æ­£åœ¨æ–°å¢ order_line_uid æ¬„ä½...")
    merged_df['order_line_uid'] = merged_df['order_sn'].astype(str) + '_' + merged_df['item_no'].astype(str).str.zfill(2)
    
    # è™•ç† note æ¬„ä½ï¼šå°‡ "é…é€å‰è«‹å…ˆé›»è¯ï¼Œè¬è¬ï¼" è¨­ç‚ºç©ºå€¼
    logger.info("æ­£åœ¨è™•ç† note æ¬„ä½...")
    if 'note' in merged_df.columns:
        # çµ±è¨ˆè™•ç†å‰çš„æ•¸é‡
        before_count = len(merged_df[merged_df['note'] == 'é…é€å‰è«‹å…ˆé›»è¯ï¼Œè¬è¬ï¼'])
        logger.info(f"æ‰¾åˆ° {before_count} ç­† note å…§å®¹ç‚º 'é…é€å‰è«‹å…ˆé›»è¯ï¼Œè¬è¬ï¼' çš„è¨˜éŒ„")
        
        # å°‡æŒ‡å®šå…§å®¹è¨­ç‚ºç©ºå€¼
        merged_df.loc[merged_df['note'] == 'é…é€å‰è«‹å…ˆé›»è¯ï¼Œè¬è¬ï¼', 'note'] = ''
        
        # çµ±è¨ˆè™•ç†å¾Œçš„æ•¸é‡
        after_count = len(merged_df[merged_df['note'] == 'é…é€å‰è«‹å…ˆé›»è¯ï¼Œè¬è¬ï¼'])
        logger.info(f"è™•ç†å®Œæˆï¼Œå‰©é¤˜ {after_count} ç­†è©²å…§å®¹çš„è¨˜éŒ„")
        logger.info(f"å·²å°‡ {before_count - after_count} ç­†è¨˜éŒ„çš„ note è¨­ç‚ºç©ºå€¼")
    else:
        logger.warning("æœªæ‰¾åˆ° note æ¬„ä½ï¼Œè·³é note è™•ç†")
    
    # è™•ç† platform æ¬„ä½ï¼šå°‡ "æ±æ£®è³¼ç‰©" è½‰æ›ç‚º "etmall"
    logger.info("æ­£åœ¨è™•ç† platform æ¬„ä½...")
    if 'platform' in merged_df.columns:
        # çµ±è¨ˆè™•ç†å‰çš„æ•¸é‡
        before_count = len(merged_df[merged_df['platform'] == 'æ±æ£®è³¼ç‰©'])
        logger.info(f"æ‰¾åˆ° {before_count} ç­† platform å…§å®¹ç‚º 'æ±æ£®è³¼ç‰©' çš„è¨˜éŒ„")
        
        # å°‡ "æ±æ£®è³¼ç‰©" è½‰æ›ç‚º "etmall"
        merged_df.loc[merged_df['platform'] == 'æ±æ£®è³¼ç‰©', 'platform'] = 'etmall'
        
        # çµ±è¨ˆè™•ç†å¾Œçš„æ•¸é‡
        after_count = len(merged_df[merged_df['platform'] == 'æ±æ£®è³¼ç‰©'])
        logger.info(f"è™•ç†å®Œæˆï¼Œå‰©é¤˜ {after_count} ç­† 'æ±æ£®è³¼ç‰©' è¨˜éŒ„")
        logger.info(f"å·²å°‡ {before_count - after_count} ç­†è¨˜éŒ„çš„ platform è½‰æ›ç‚º 'etmall'")
        
        # çµ±è¨ˆè½‰æ›å¾Œçš„ etmall æ•¸é‡
        etmall_count = len(merged_df[merged_df['platform'] == 'etmall'])
        logger.info(f"è½‰æ›å¾Œå…±æœ‰ {etmall_count} ç­† 'etmall' è¨˜éŒ„")
    else:
        logger.warning("æœªæ‰¾åˆ° platform æ¬„ä½ï¼Œè·³é platform è™•ç†")
    
    # é‡æ–°æ’åˆ—æ¬„ä½é †åº
    logger.info("æ­£åœ¨é‡æ–°æ’åˆ—æ¬„ä½é †åº...")
    
    # å®šç¾©ç›®æ¨™æ¬„ä½é †åºï¼ˆæŒ‰ç…§ä¹‹å‰æŒ‡å®šçš„é•·ä¸²é †åºï¼Œä½†åªä¿ç•™æŒ‡å®šçš„æ¬„ä½ï¼‰
    target_columns = [
        'platform', 'order_date', 'order_sn', 'item_no', 'order_line_uid',
        'seller_product_sn', 'product_name_platform', 'quantity', 'unit_price',
        'customer_name', 'customer_phone', 'shipping_address', 'note',
        'cost_to_platform', 'delivery_company'
    ]
    
    # æª¢æŸ¥ç¾æœ‰æ¬„ä½
    existing_columns = list(merged_df.columns)
    logger.info(f"ç¾æœ‰æ¬„ä½æ•¸é‡ï¼š{len(existing_columns)}")
    logger.info(f"ç¾æœ‰æ¬„ä½ï¼š{existing_columns}")
    
    # åªä¿ç•™æŒ‡å®šçš„æ¬„ä½ï¼Œç§»é™¤å…¶ä»–æ¬„ä½
    merged_df = merged_df[target_columns]
    
    logger.info(f"é‡æ–°æ’åˆ—å¾Œæ¬„ä½æ•¸é‡ï¼š{len(merged_df.columns)}")
    logger.info(f"é‡æ–°æ’åˆ—å¾Œæ¬„ä½ï¼š{list(merged_df.columns)}")
    
    return merged_df

def save_merged_file(merged_df, output_dir, logger):
    """å„²å­˜åˆä½µå¾Œçš„æª”æ¡ˆ"""
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = output_dir / f"etmall_order_report_merged_{timestamp}.csv"
    
    try:
        # ç¢ºä¿æ‰€æœ‰è³‡æ–™éƒ½æ˜¯å­—ä¸²æ ¼å¼
        for col in merged_df.columns:
            merged_df[col] = merged_df[col].astype(str)
        
        merged_df.to_csv(output_file, index=False, encoding='utf-8-sig', na_rep='')
        logger.info(f"åˆä½µæª”æ¡ˆå·²å„²å­˜è‡³: {output_file}")
        return output_file
    except Exception as e:
        logger.error(f"å„²å­˜æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return None

def remove_order_report_directory(order_report_dir, logger):
    """ç§»é™¤ Order_Report ç›®éŒ„åŠå…¶å…§å®¹"""
    try:
        order_report_path = Path(order_report_dir)
        if order_report_path.exists():
            # è¨ˆç®—ç›®éŒ„å¤§å°
            total_size = 0
            file_count = 0
            for root, dirs, files in os.walk(order_report_path):
                for file in files:
                    file_path = Path(root) / file
                    total_size += file_path.stat().st_size
                    file_count += 1
            
            # ç­‰å¾…ä¸€ä¸‹ç¢ºä¿æª”æ¡ˆå¥æŸ„è¢«é‡‹æ”¾
            logger.info("ç­‰å¾…æª”æ¡ˆå¥æŸ„é‡‹æ”¾...")
            time.sleep(2)
            
            # ç§»é™¤ç›®éŒ„åŠå…¶å…§å®¹
            shutil.rmtree(order_report_path)
            logger.info(f"å·²ç§»é™¤ Order_Report ç›®éŒ„: {order_report_dir}")
            logger.info(f"ç§»é™¤æª”æ¡ˆæ•¸é‡: {file_count} å€‹")
            logger.info(f"ç§»é™¤ç¸½å¤§å°: {total_size / 1024 / 1024:.2f} MB")
            return True
        else:
            logger.warning(f"Order_Report ç›®éŒ„ä¸å­˜åœ¨: {order_report_dir}")
            return False
    except Exception as e:
        logger.error(f"ç§»é™¤ Order_Report ç›®éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•¸"""
    logger = setup_logging()
    logger.info("é–‹å§‹åŸ·è¡Œæ±æ£®è³¼ç‰©è¨‚å–®å ±è¡¨åˆä½µè…³æœ¬")
    
    # è¨­å®šè·¯å¾‘
    base_dir = "temp/etmall/Order_Report"
    output_dir = "temp/etmall"
    
    # æª¢æŸ¥è¼¸å…¥ç›®éŒ„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(base_dir):
        logger.error(f"è¼¸å…¥ç›®éŒ„ä¸å­˜åœ¨: {base_dir}")
        logger.info("è«‹å…ˆåŸ·è¡Œ 02_01_etmall_order_report_cleaner.py è…³æœ¬")
        return
    
    # æœå°‹æ‰€æœ‰ CSV æª”æ¡ˆ
    logger.info(f"æ­£åœ¨æœå°‹ç›®éŒ„: {base_dir}")
    csv_files = find_csv_files(base_dir)
    
    if not csv_files:
        logger.warning(f"åœ¨ç›®éŒ„ {base_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½• CSV æª”æ¡ˆ")
        return
    
    logger.info(f"æ‰¾åˆ° {len(csv_files)} å€‹ CSV æª”æ¡ˆ")
    
    # é¡¯ç¤ºæ‰¾åˆ°çš„æª”æ¡ˆåˆ—è¡¨
    logger.info("æ‰¾åˆ°çš„æª”æ¡ˆåˆ—è¡¨:")
    for i, file_path in enumerate(csv_files, 1):
        file_size = Path(file_path).stat().st_size / 1024  # KB
        logger.info(f"  {i:2d}. {file_path} ({file_size:.2f} KB)")
    
    # è™•ç†ä¸¦åˆä½µæ‰€æœ‰ CSV æª”æ¡ˆ
    merged_df = merge_csv_files(csv_files, logger)
    
    if merged_df is None:
        logger.error("åˆä½µå¤±æ•—")
        return
    
    # é¡¯ç¤ºåˆä½µå¾Œçš„æ¬„ä½è³‡è¨Š
    logger.info("åˆä½µå¾Œçš„æ¬„ä½é †åº:")
    for i, col in enumerate(merged_df.columns):
        logger.info(f"  {i+1:2d}. {col}")
    
    # é¡¯ç¤ºè³‡æ–™çµ±è¨ˆ
    logger.info("è³‡æ–™çµ±è¨ˆ:")
    logger.info(f"  ç¸½è³‡æ–™ç­†æ•¸: {len(merged_df)}")
    logger.info(f"  ç¸½æ¬„ä½æ•¸: {len(merged_df.columns)}")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰é‡è¤‡çš„ order_sn
    if 'order_sn' in merged_df.columns:
        unique_order_sns = merged_df['order_sn'].nunique()
        total_order_sns = len(merged_df)
        logger.info(f"  å”¯ä¸€ order_sn æ•¸é‡: {unique_order_sns}")
        logger.info(f"  é‡è¤‡ order_sn æ•¸é‡: {total_order_sns - unique_order_sns}")
    
    # å„²å­˜åˆä½µå¾Œçš„æª”æ¡ˆ
    output_file = save_merged_file(merged_df, output_dir, logger)
    
    if output_file:
        logger.info("åˆä½µæª”æ¡ˆå„²å­˜æˆåŠŸï¼")
        logger.info(f"è¼¸å‡ºæª”æ¡ˆ: {output_file}")
        logger.info(f"æª”æ¡ˆå¤§å°: {Path(output_file).stat().st_size / 1024 / 1024:.2f} MB")
        
        # ç§»é™¤ Order_Report ç›®éŒ„åŠå…¶å…§å®¹
        logger.info("é–‹å§‹ç§»é™¤ Order_Report ç›®éŒ„...")
        if remove_order_report_directory(base_dir, logger):
            logger.info("âœ… è…³æœ¬åŸ·è¡Œå®Œæˆï¼")
            logger.info(f"ğŸ“ åˆä½µæª”æ¡ˆ: {output_file}")
            logger.info(f"ğŸ“Š ç¸½è³‡æ–™ç­†æ•¸: {len(merged_df)}")
            logger.info(f"ğŸ—‘ï¸ å·²ç§»é™¤åŸå§‹ Order_Report ç›®éŒ„")
        else:
            logger.error("âŒ ç§»é™¤ Order_Report ç›®éŒ„å¤±æ•—")
    else:
        logger.error("âŒ è…³æœ¬åŸ·è¡Œå¤±æ•—")

if __name__ == "__main__":
    main()
