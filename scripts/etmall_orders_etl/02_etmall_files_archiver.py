#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ±æ£®è³¼ç‰©æª”æ¡ˆæ­¸æª”è…³æœ¬ - æŒ‰æª”æ¡ˆåç¨±æ™‚é–“ç§»å‹•åˆ°å¹´æœˆè³‡æ–™å¤¾

å°‡ data_raw\etmall ä¸‹çš„æª”æ¡ˆæŒ‰æª”æ¡ˆåç¨±ä¸­çš„æ™‚é–“ç§»å‹•åˆ°å°æ‡‰çš„å¹´æœˆè³‡æ–™å¤¾
"""

import sys
import logging
import pandas as pd
from datetime import datetime
from pathlib import Path
from typing import List, Dict
import re
import shutil

def setup_logging():
    """è¨­å®šæ—¥èªŒ"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('logs/etmall_archiver.log', encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)

def extract_date_from_filename(filename: str) -> datetime:
    """å¾æª”åä¸­æå–æ—¥æœŸ"""
    # å˜—è©¦å¾æª”åä¸­æå–æ—¥æœŸ
    date_patterns = [
        r'(\d{8})',  # YYYYMMDD
        r'(\d{4})_(\d{2})',  # YYYY_MM
        r'(\d{4})-(\d{2})',  # YYYY-MM
    ]
    
    for pattern in date_patterns:
        match = re.search(pattern, filename)
        if match:
            if len(match.groups()) == 1:
                # YYYYMMDD æ ¼å¼
                date_str = match.group(1)
                if len(date_str) == 8:
                    return datetime.strptime(date_str, '%Y%m%d')
            elif len(match.groups()) == 2:
                # YYYY_MM æˆ– YYYY-MM æ ¼å¼
                year = match.group(1)
                month = match.group(2)
                return datetime.strptime(f"{year}{month}01", '%Y%m%d')
    
    # å¦‚æœç„¡æ³•å¾æª”åæå–ï¼Œè¿”å› None
    return None

def compare_file_content(file1_path: Path, file2_path: Path) -> bool:
    """æ¯”è¼ƒå…©å€‹æª”æ¡ˆçš„å…§å®¹æ˜¯å¦ç›¸åŒ"""
    try:
        # è®€å–å…©å€‹æª”æ¡ˆçš„å…§å®¹
        if file1_path.suffix.lower() in ['.xls', '.xlsx']:
            df1 = pd.read_excel(file1_path)
        else:
            df1 = pd.read_csv(file1_path, encoding='utf-8')
        
        if file2_path.suffix.lower() in ['.xls', '.xlsx']:
            df2 = pd.read_excel(file2_path)
        else:
            df2 = pd.read_csv(file2_path, encoding='utf-8')
        
        # æ¯”è¼ƒ DataFrame æ˜¯å¦ç›¸åŒ
        return df1.equals(df2)
        
    except Exception as e:
        logging.warning(f"ç„¡æ³•æ¯”è¼ƒæª”æ¡ˆå…§å®¹ {file1_path} vs {file2_path}: {e}")
        return False

def detect_file_type(file_path: Path) -> str:
    """æª¢æ¸¬æª”æ¡ˆé¡å‹"""
    # é¦–å…ˆæ ¹æ“šæª”ååˆ¤æ–·ï¼ˆå„ªå…ˆç´šæœ€é«˜ï¼‰
    filename = file_path.name.lower()
    if 'è¨‚å–®å‡ºè²¨å ±è¡¨' in filename or 'å‡ºè²¨' in filename:
        return "daily_shipping_orders"
    elif 'éŠ·å”®å ±è¡¨' in filename or 'éŠ·å”®' in filename:
        return "sales_report"
    
    # å¦‚æœæª”åç„¡æ³•åˆ¤æ–·ï¼Œå†æ ¹æ“šæª”æ¡ˆå…§å®¹åˆ¤æ–·
    try:
        if file_path.suffix.lower() in ['.xls', '.xlsx']:
            df = pd.read_excel(file_path, nrows=5)
        else:
            df = pd.read_csv(file_path, nrows=5, encoding='utf-8')
        
        columns = [str(col).strip() for col in df.columns]
        
        # è¨‚å–®å‡ºè²¨å ±è¡¨åˆ¤å®šï¼šåŒ…å«ç‰¹å®šæ¬„ä½
        order_report_indicators = [
            'è¨‚å–®è™Ÿç¢¼', 'è¨‚å–®é …æ¬¡', 'ä½µå–®åºè™Ÿ', 'é€è²¨å–®è™Ÿ', 'éŠ·å”®ç·¨è™Ÿ', 
            'å•†å“ç·¨è™Ÿ', 'å•†å“åç¨±', 'é¡è‰²', 'æ¬¾å¼', 'å» å•†å•†å“è™Ÿç¢¼', 
            'è¨‚å–®é¡åˆ¥', 'æ•¸é‡', 'å”®åƒ¹', 'æˆæœ¬', 'å®¢æˆ¶åç¨±', 'å®¢æˆ¶é›»è©±', 
            'å®¤å…§é›»è©±', 'é…é€åœ°å€', 'è²¨é‹å…¬å¸', 'é…é€å–®è™Ÿ', 'å‡ºè²¨æŒ‡ç¤ºæ—¥', 
            'è¦æ±‚é…é€æ—¥', 'è¦æ±‚é…é€æ™‚é–“', 'å‚™è¨»', 'è´ˆå“', 'å» å•†é…é€è¨Šæ¯', 
            'é è¨ˆå…¥åº«æ—¥', 'é è¨ˆé…é€æ—¥', 'é€šè·¯åˆ¥', 'è¨‚å–®é¡åˆ¥ä»£è™Ÿ', 'å…¬å¸åˆ¥'
        ]
        
        # éŠ·å”®å ±è¡¨åˆ¤å®šï¼šåŒ…å«ç‰¹å®šæ¬„ä½
        sales_report_indicators = [
            'è¨‚å–®æ—¥æœŸ', 'è¨‚å–®ç·¨è™Ÿ', 'é …æ¬¡', 'é…é€ç‹€æ…‹', 'è¨‚å–®ç‹€æ…‹', 
            'å•†å“å±¬æ€§', 'éŠ·å”®ç·¨è™Ÿ', 'å­å•†å“éŠ·å”®ç·¨è™Ÿ', 'å­å•†å“å•†å“ç·¨è™Ÿ', 
            'é…é€æ–¹å¼', 'å•†å“åç¨±', 'é¡è‰²', 'æ¬¾å¼', 'å”®åƒ¹', 'æˆæœ¬', 
            'æ•¸é‡', 'é€šè·¯', 'é…é€ç¢ºèªæ—¥', 'å…¬å¸'
        ]
        
        # è¨ˆç®—åŒ¹é…æ•¸é‡
        order_match_count = sum(1 for indicator in order_report_indicators if any(indicator in col for col in columns))
        sales_match_count = sum(1 for indicator in sales_report_indicators if any(indicator in col for col in columns))
        
        # æ ¹æ“šåŒ¹é…æ•¸é‡åˆ¤æ–·é¡å‹
        if order_match_count >= 6:
            return "daily_shipping_orders"
        elif sales_match_count >= 6:
            return "sales_report"
        else:
            # å¦‚æœå…§å®¹ä¹Ÿç„¡æ³•åˆ¤æ–·ï¼Œé è¨­ç‚ºè¨‚å–®å‡ºè²¨å ±è¡¨
            return "daily_shipping_orders"
            
    except Exception as e:
        logging.warning(f"ç„¡æ³•æª¢æ¸¬æª”æ¡ˆé¡å‹ {file_path}: {e}")
        # é è¨­ç‚ºè¨‚å–®å‡ºè²¨å ±è¡¨
        return "daily_shipping_orders"

def archive_files_to_folders(logger: logging.Logger):
    """å°‡æª”æ¡ˆæŒ‰é¡å‹ç§»å‹•åˆ°å°æ‡‰çš„å¹´æœˆè³‡æ–™å¤¾"""
    base_path = Path("data_raw/etmall")
    
    if not base_path.exists():
        logger.error(f"ç›®éŒ„ä¸å­˜åœ¨: {base_path}")
        return
    
    # ç²å–æ‰€æœ‰æª”æ¡ˆï¼ˆæ’é™¤ archive å’Œ backup ç›®éŒ„ï¼‰
    files = []
    for file_path in base_path.rglob("*"):
        if file_path.is_file() and file_path.suffix.lower() in ['.csv', '.xls', '.xlsx']:
            # æ’é™¤ archive å’Œ backup ç›®éŒ„ä¸­çš„æª”æ¡ˆ
            if 'archive' not in file_path.parts and 'backup' not in file_path.parts:
                files.append(file_path)
    
    logger.info(f"æ‰¾åˆ° {len(files)} å€‹æª”æ¡ˆéœ€è¦æ­¸æª”")
    
    created_folders = set()
    moved_count = 0
    skipped_count = 0
    duplicate_content_count = 0
    
    for file_path in files:
        try:
            # å¾æª”åæå–æ—¥æœŸ
            file_date = extract_date_from_filename(file_path.name)
            if not file_date:
                logger.warning(f"ç„¡æ³•å¾æª”åæå–æ—¥æœŸï¼Œè·³é: {file_path.name}")
                skipped_count += 1
                continue
            
            # æª¢æ¸¬æª”æ¡ˆé¡å‹
            file_type = detect_file_type(file_path)
            logger.info(f"ğŸ“‹ æª”æ¡ˆé¡å‹: {file_path.name} -> {file_type}")
            
            # ç¢ºå®šæ­¸æª”ç›®éŒ„ï¼šæŒ‰é¡å‹/å¹´/æœˆçµ„ç¹”ï¼ˆéŠ·å”®å ±è¡¨åªæŒ‰å¹´ï¼‰
            if file_type == "sales_report":
                # éŠ·å”®å ±è¡¨ï¼šåªæŒ‰å¹´æ­¸æª”
                archive_dir = base_path / file_type / str(file_date.year)
            else:
                # è¨‚å–®å‡ºè²¨å ±è¡¨ï¼šæŒ‰å¹´/æœˆæ­¸æª”
                archive_dir = base_path / file_type / str(file_date.year) / f"{file_date.month:02d}"
            
            # å‰µå»ºæ­¸æª”ç›®éŒ„ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            if not archive_dir.exists():
                archive_dir.mkdir(parents=True, exist_ok=True)
                created_folders.add(str(archive_dir))
                logger.info(f"ğŸ“ å‰µå»ºæ­¸æª”ç›®éŒ„: {archive_dir}")
            
            # æª¢æŸ¥ç›®æ¨™è³‡æ–™å¤¾æ˜¯å¦å·²æœ‰åŒåæª”æ¡ˆ
            target_file_path = archive_dir / file_path.name
            if target_file_path.exists():
                # æª¢æŸ¥å…§å®¹æ˜¯å¦é‡è¤‡
                if compare_file_content(file_path, target_file_path):
                    logger.warning(f"âš ï¸ å…§å®¹é‡è¤‡ï¼Œè·³é: {file_path.name} (èˆ‡ {target_file_path} å…§å®¹ç›¸åŒ)")
                    duplicate_content_count += 1
                    continue
                else:
                    # å…§å®¹ä¸åŒï¼Œç”Ÿæˆæ–°çš„æª”å
                    counter = 1
                    while (archive_dir / f"{file_path.stem}_{counter:03d}{file_path.suffix}").exists():
                        counter += 1
                    target_file_path = archive_dir / f"{file_path.stem}_{counter:03d}{file_path.suffix}"
                    logger.info(f"ğŸ“ å…§å®¹ä¸åŒï¼Œä½¿ç”¨æ–°æª”å: {target_file_path.name}")
            
            # ç§»å‹•æª”æ¡ˆåˆ°æ­¸æª”ç›®éŒ„
            shutil.move(str(file_path), str(target_file_path))
            
            logger.info(f"âœ… å·²ç§»å‹•: {file_path.name} -> {target_file_path}")
            moved_count += 1
            
        except Exception as e:
            logger.error(f"ç§»å‹•å¤±æ•— {file_path}: {e}")
            skipped_count += 1
    
    logger.info(f"âœ… æª”æ¡ˆæ­¸æª”å®Œæˆï¼")
    logger.info(f"   - æˆåŠŸç§»å‹•: {moved_count} å€‹æª”æ¡ˆ")
    logger.info(f"   - å…§å®¹é‡è¤‡è·³é: {duplicate_content_count} å€‹æª”æ¡ˆ")
    logger.info(f"   - å…¶ä»–è·³é: {skipped_count} å€‹æª”æ¡ˆ")
    logger.info(f"   - å‰µå»ºè³‡æ–™å¤¾: {len(created_folders)} å€‹")
    
    # é¡¯ç¤ºå‰µå»ºçš„æ­¸æª”ç›®éŒ„çµæ§‹
    logger.info(f"ğŸ“ æ­¸æª”ç›®éŒ„çµæ§‹:")
    for type_dir in sorted(base_path.iterdir()):
        if type_dir.is_dir() and type_dir.name not in ['backup', 'archive']:
            logger.info(f"   {type_dir.name}/")
            type_total = 0
            for year_dir in sorted(type_dir.iterdir()):
                if year_dir.is_dir():
                    if type_dir.name == "sales_report":
                        # éŠ·å”®å ±è¡¨ï¼šåªé¡¯ç¤ºå¹´ä»½å’Œæª”æ¡ˆæ•¸é‡
                        year_files = len(list(year_dir.glob("*")))
                        if year_files > 0:
                            logger.info(f"     {year_dir.name}: {year_files} å€‹æª”æ¡ˆ")
                            type_total += year_files
                    else:
                        # è¨‚å–®å‡ºè²¨å ±è¡¨ï¼šé¡¯ç¤ºå¹´/æœˆå’Œæª”æ¡ˆæ•¸é‡
                        year_total = 0
                        for month_dir in sorted(year_dir.iterdir()):
                            if month_dir.is_dir():
                                month_files = len(list(month_dir.glob("*")))
                                if month_files > 0:
                                    logger.info(f"       {year_dir.name}/{month_dir.name}: {month_files} å€‹æª”æ¡ˆ")
                                    year_total += month_files
                        if year_total > 0:
                            logger.info(f"     {year_dir.name}/: ç¸½è¨ˆ {year_total} å€‹æª”æ¡ˆ")
                            type_total += year_total
            if type_total > 0:
                logger.info(f"   {type_dir.name}/: ç¸½è¨ˆ {type_total} å€‹æª”æ¡ˆ")

def main():
    """ä¸»å‡½æ•¸"""
    logger = setup_logging()
    
    logger.info("ğŸš€ é–‹å§‹åŸ·è¡Œæ±æ£®è³¼ç‰©æª”æ¡ˆæ­¸æª”è…³æœ¬")
    
    try:
        archive_files_to_folders(logger)
        logger.info("âœ… æ­¸æª”è…³æœ¬åŸ·è¡Œå®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ æ­¸æª”è…³æœ¬åŸ·è¡Œå¤±æ•—: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()