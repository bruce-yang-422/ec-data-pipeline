# scripts/etmall_orders_etl/etmall_orders_cleaner.py
# -*- coding: utf-8 -*-
"""
æ±æ£®è³¼ç‰©è¨‚å–®è³‡æ–™åº«æ¸…æ´—è…³æœ¬
"""

import pandas as pd
import json
import sys
import logging
from datetime import datetime
from pathlib import Path
import re

def is_valid_date(val):
    if isinstance(val, str) and re.match(r'^\d{4}-\d{2}-\d{2}( \d{2}:\d{2}(:\d{2})?)?$', val.strip()):
        return True
    return False

class EtmallOrdersCleaner:
    def __init__(self):
        self.script_dir = Path(__file__).parent
        self.project_root = self.script_dir.parents[1]
        self.mapping_path = self.project_root / "config" / "etmall_fields_mapping.json"
        self.source_dir = self.project_root / "data_raw" / "etmall"
        self.output_dir = self.project_root / "data_processed" / "merged"
        self.output_path = self.output_dir / "etmall_orders_cleaned.csv"
        self.logs_dir = self.project_root / "logs"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.logs_dir.mkdir(parents=True, exist_ok=True)
        self.setup_logging()

    def setup_logging(self):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_filename = f"etmall_orders_cleaner_{timestamp}.log"
        log_path = self.logs_dir / log_filename
        file_handler = logging.FileHandler(log_path, encoding='utf-8')
        file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
        logging.basicConfig(level=logging.INFO, handlers=[file_handler, console_handler])
        self.logger = logging.getLogger(__name__)
        self.logger.info("=== æ±æ£®è³¼ç‰©è¨‚å–®è³‡æ–™åº«æ¸…æ´—é–‹å§‹ ===")

    def get_mapping(self):
        with open(self.mapping_path, "r", encoding="utf-8") as f:
            mapping = json.load(f)
        mapping = {k.strip(): v for k, v in mapping.items()}
        columns = []
        for k, v in sorted(mapping.items(), key=lambda item: int(item[1]["order"])):
            if k not in columns:
                columns.append(k)
        self.logger.info(f"è¼‰å…¥ mapping é…ç½®ï¼š{len(mapping)} å€‹æ¬„ä½, æ¬„ä½é †åº: {columns}")
        return mapping, columns

    def read_csv_files(self) -> pd.DataFrame:
        csv_files = list(self.source_dir.glob("*.csv"))
        if not csv_files:
            self.logger.warning(f"åœ¨ {self.source_dir} ç›®éŒ„ä¸‹æ²’æœ‰æ‰¾åˆ° CSV æª”æ¡ˆ")
            return pd.DataFrame()
        self.logger.info(f"æ‰¾åˆ° {len(csv_files)} å€‹ CSV æª”æ¡ˆ")
        dfs = []
        for file_path in csv_files:
            try:
                file_name = file_path.name
                self.logger.info(f"è™•ç†æª”æ¡ˆï¼š{file_name}")
                df = None
                encodings = ['utf-8-sig', 'utf-8', 'cp950', 'big5', 'gbk', 'gb2312']
                for encoding in encodings:
                    try:
                        df = pd.read_csv(file_path, dtype=str, encoding=encoding)
                        df.columns = [col.strip() for col in df.columns]
                        self.logger.info(f"æˆåŠŸä½¿ç”¨ç·¨ç¢¼ï¼š{encoding}")
                        break
                    except UnicodeDecodeError:
                        continue
                    except Exception as e:
                        self.logger.warning(f"ç·¨ç¢¼ {encoding} è®€å–å¤±æ•—ï¼š{e}")
                        continue
                if df is None:
                    self.logger.error(f"ç„¡æ³•è®€å–æª”æ¡ˆï¼š{file_name}ï¼Œæ‰€æœ‰ç·¨ç¢¼éƒ½å¤±æ•—")
                    continue
                df = df.fillna('')
                df = df.replace(['', 'nan', 'NaN'], '')
                for col in df.columns:
                    if df[col].dtype == 'object':
                        df[col] = df[col].astype(str).str.replace('\n', ' ').str.replace('\r', ' ').str.strip()
                df['data_source'] = file_name
                dfs.append(df)
                self.logger.info(f"è®€å–æˆåŠŸï¼š{file_name} ({len(df)} ç­†)")
            except Exception as e:
                self.logger.error(f"è®€å–å¤±æ•—ï¼š{file_path} - {e}")
        if not dfs:
            return pd.DataFrame()
        combined_df = pd.concat(dfs, ignore_index=True)
        self.logger.info(f"ç¸½å…±è®€å– {len(combined_df)} ç­†åŸå§‹è³‡æ–™")
        return combined_df

    def map_columns(self, df: pd.DataFrame, mapping: dict) -> pd.DataFrame:
        zh2en = {v["zh_name"].strip(): en for en, v in mapping.items() if "zh_name" in v}
        rename_dict = {}
        for col in df.columns:
            col_strip = col.strip()
            if col_strip in zh2en:
                rename_dict[col] = zh2en[col_strip]
        df = df.rename(columns=rename_dict)
        df = df.loc[:, ~df.columns.duplicated()]
        self.logger.info(f"map_columnså¾Œæ¬„ä½: {df.columns.tolist()}")
        return df

    def generate_order_line_uid(self, df: pd.DataFrame) -> pd.DataFrame:
        if 'order_sn' in df.columns and 'line_number' in df.columns:
            df['order_line_uid'] = df['order_sn'].astype(str) + '_' + df['line_number'].astype(str)
        elif 'order_sn' in df.columns:
            df['order_line_uid'] = df['order_sn'].astype(str)
            df['line_number'] = 1
        else:
            self.logger.warning("ç„¡æ³•ç”Ÿæˆ order_line_uidï¼Œç¼ºå°‘å¿…è¦æ¬„ä½")
            df['order_line_uid'] = ''
            df['line_number'] = 1
        return df

    def standardize_date_format(self, date_str):
        if not isinstance(date_str, str) or not date_str.strip():
            return ""
        try:
            date_str = str(date_str).strip()
            if len(date_str) >= 10 and '-' in date_str:
                return date_str
            if '/' in date_str:
                parts = date_str.split('/')
                if len(parts) >= 3:
                    year, month, day = parts[:3]
                    return f"{int(year):04d}-{int(month):02d}-{int(day):02d}"
            if len(date_str) == 8 and date_str.isdigit():
                year = date_str[:4]
                month = date_str[4:6]
                day = date_str[6:8]
                return f"{year}-{month}-{day}"
            return date_str
        except:
            return ""

    def process_data(self, df: pd.DataFrame, mapping: dict, columns: list) -> pd.DataFrame:
        self.logger.info("é–‹å§‹è³‡æ–™è™•ç†...")
        df['platform'] = 'etmall'
        df['processing_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        # === åªè£œä¸­æ–‡åŸå§‹æ¬„ä½ï¼ˆmapping.zh_nameï¼‰ï¼Œä¸è£œè‹±æ–‡ key ===
        zh_names = [v["zh_name"].strip() for k, v in mapping.items() if "zh_name" in v]
        for zh in zh_names:
            if zh not in df.columns:
                df[zh] = ''
        self.logger.info(f"process_dataè£œé½Šæ¬„ä½å¾Œ: {df.columns.tolist()}")

        # mapping ä¸­æ–‡è½‰è‹±æ–‡
        df = self.map_columns(df, mapping)

        # === è£œè‹±æ–‡æ¬„ä½ï¼ˆå¦‚ç¨‹å¼è‡ªå‹•ç”Ÿæˆæ¬„ä½ï¼šorder_line_uidã€platform...ï¼‰===
        for col in columns:
            if col not in df.columns:
                if col == 'shipping_confirmation_date':
                    df[col] = ''
                elif col in ['unit_price', 'cost']:
                    df[col] = 0
                elif col in ['quantity']:
                    df[col] = 1
                elif col in ['line_number']:
                    df[col] = 1
                else:
                    df[col] = ''

        df = self.generate_order_line_uid(df)
        if 'order_date' in df.columns:
            self.logger.info("æ¨™æº–åŒ–è¨‚å–®æ—¥æœŸæ ¼å¼")
            df['order_date'] = df['order_date'].apply(self.standardize_date_format)
        numeric_fields = ['unit_price', 'cost', 'quantity']
        for field in numeric_fields:
            if field in df.columns:
                try:
                    df[field] = pd.to_numeric(df[field], errors='coerce')
                    if field == 'quantity':
                        df[field] = df[field].fillna(1).astype(int)
                    else:
                        df[field] = df[field].fillna(0)
                except Exception as e:
                    self.logger.warning(f"è™•ç†æ•¸å€¼æ¬„ä½ {field} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

        if 'order_sn' in df.columns:
            before_filter = len(df)
            df = df[df['order_sn'].astype(str).str.strip() != ""]
            self.logger.info(f"éæ¿¾ç©ºè¨‚å–®ç·¨è™Ÿï¼š{before_filter} -> {len(df)} ç­†")

        self.logger.info(f"è³‡æ–™è™•ç†å®Œæˆï¼Œå…± {len(df)} ç­†è³‡æ–™")
        return df

    def check_duplicates(self, df: pd.DataFrame) -> pd.DataFrame:
        if 'order_line_uid' not in df.columns:
            self.logger.warning("ç„¡æ³•æª¢æŸ¥é‡è¤‡ï¼Œç¼ºå°‘ order_line_uid æ¬„ä½")
            return df
        before_dedup = len(df)
        duplicates = df[df['order_line_uid'].duplicated(keep=False)]
        if len(duplicates) > 0:
            self.logger.warning(f"ç™¼ç¾ {len(duplicates)} ç­†é‡è¤‡è³‡æ–™")
            df = df.sort_values('processing_date', ascending=False).drop_duplicates(
                subset=['order_line_uid'], keep='first'
            )
            self.logger.info(f"å»é‡å¾Œï¼š{before_dedup} -> {len(df)} ç­†")
        else:
            self.logger.info("ç„¡é‡è¤‡è³‡æ–™")
        return df

    def merge_with_existing(self, df: pd.DataFrame) -> pd.DataFrame:
        if not self.output_path.exists():
            self.logger.info("è¼¸å‡ºæª”æ¡ˆä¸å­˜åœ¨ï¼Œç›´æ¥å„²å­˜æ–°è³‡æ–™")
            return df
        try:
            existing_df = pd.read_csv(self.output_path, dtype=str)
            self.logger.info(f"è®€å–ç¾æœ‰è³‡æ–™ï¼š{len(existing_df)} ç­†")
            combined_df = pd.concat([existing_df, df], ignore_index=True)
            self.logger.info(f"åˆä½µå¾Œè³‡æ–™ï¼š{len(combined_df)} ç­†")
            combined_df = self.check_duplicates(combined_df)
            if 'shipping_confirmation_date' in combined_df.columns:
                combined_df['shipping_confirmation_date'] = combined_df['shipping_confirmation_date'].astype(str)
                combined_df['shipping_confirmation_date'] = combined_df['shipping_confirmation_date'].replace(['nan', 'NaN', 'NaT', 'None'], '').fillna('')
            return combined_df
        except Exception as e:
            self.logger.error(f"åˆä½µç¾æœ‰è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return df

    def save_data(self, df: pd.DataFrame, columns: list, mapping: dict):
        try:
            self.output_dir.mkdir(parents=True, exist_ok=True)
            # æ¬„ä½å”¯ä¸€ä¸”é †åºæ­£ç¢º
            df_columns_seen = set()
            available_columns = []
            for col in columns:
                if col in df.columns and col not in df_columns_seen:
                    available_columns.append(col)
                    df_columns_seen.add(col)
            df_output = df[available_columns].copy()
            self.logger.info(f"save_data æ¬„ä½: {df_output.columns.tolist()}")
            if 'shipping_confirmation_date' in df_output.columns:
                df_output['shipping_confirmation_date'] = df_output['shipping_confirmation_date'].astype(str)
                df_output['shipping_confirmation_date'] = df_output['shipping_confirmation_date'].replace(['nan', 'NaN', 'NaT', 'None'], '').fillna('')
            if 'order_date' in df_output.columns:
                # æ’åºæ™‚ç”¨ to_datetimeï¼Œä½†æ¬„ä½å…§å®¹æœ¬èº«ä¸æœƒå¡«é è¨­
                df_output = df_output.sort_values('order_date', key=lambda x: pd.to_datetime(x, errors='coerce'), ascending=True, na_position='first')
                # æ ¼å¼åŒ–é¡¯ç¤º
                def fmt_date(x):
                    try:
                        dt = pd.to_datetime(x, errors='coerce')
                        return dt.strftime('%Y-%m-%d %H:%M:%S') if pd.notnull(dt) else ''
                    except:
                        return ''
                df_output['order_date'] = df_output['order_date'].apply(fmt_date)
            df_output.to_csv(self.output_path, index=False, encoding='utf-8-sig')
            self.logger.info(f"âœ… è³‡æ–™å„²å­˜æˆåŠŸï¼š{self.output_path}")
            self.logger.info(f"ğŸ“Š è³‡æ–™çµ±è¨ˆï¼š{len(df_output)} ç­†ï¼Œ{len(df_output.columns)} æ¬„")
        except Exception as e:
            self.logger.error(f"å„²å­˜è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            raise

    def run(self):
        try:
            mapping, columns = self.get_mapping()
            df = self.read_csv_files()
            if df.empty:
                self.logger.warning("æ²’æœ‰æ‰¾åˆ°å¯è™•ç†çš„è³‡æ–™")
                return
            df = self.process_data(df, mapping, columns)
            df = self.merge_with_existing(df)
            self.save_data(df, columns, mapping)
            self.logger.info("=== æ±æ£®è³¼ç‰©è¨‚å–®è³‡æ–™åº«æ¸…æ´—å®Œæˆ ===")
        except Exception as e:
            self.logger.error(f"åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            raise

def main():
    cleaner = EtmallOrdersCleaner()
    cleaner.run()

if __name__ == "__main__":
    main()
