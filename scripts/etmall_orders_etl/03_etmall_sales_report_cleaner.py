#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ±æ£®è³¼ç‰©éŠ·å”®å ±è¡¨æ¸…æ´—è…³æœ¬

æ¸…æ´— data_raw/etmall/sales_report ä¸‹æ‰€æœ‰æª”æ¡ˆåŠä¸‹é¢è³‡æ–™å¤¾å…§æª”æ¡ˆ
åªä¿ç•™æŒ‡å®šçš„ 14 å€‹æ¬„ä½ï¼š
- delivery_company, order_sn, seller_product_sn, product_name_platform
- quantity, unit_price, customer_name, shipping_address, customer_day_phone
- platform, note, order_amount, cost_to_platform, order_date
è¼¸å‡ºåˆ° temp/etmall/Sales_Report ç›®éŒ„
order_date è½‰æ›ç‚º DATE è³‡æ–™å‹æ…‹ï¼Œå…¶ä»–æ¬„ä½ä¿æŒå­—ä¸²æ ¼å¼
"""

import sys
import logging
import pandas as pd
from datetime import datetime
from pathlib import Path
from typing import List
import re
import shutil

def setup_logging() -> None:
    """è¨­å®šæ—¥èªŒ"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )

def is_valid_column_name(column_name: str) -> bool:
    """æª¢æŸ¥æ¬„ä½åç¨±æ˜¯å¦ç‚ºæœ‰æ•ˆçš„è‹±æ–‡æ¬„ä½åç¨±"""
    # ç§»é™¤ç©ºç™½ä¸¦è½‰æ›ç‚ºå­—ä¸²
    column_name = str(column_name).strip()
    
    # æª¢æŸ¥æ˜¯å¦ç‚ºç©ºæˆ– NaN
    if not column_name or column_name.lower() in ['nan', 'none', 'null', '']:
        return False
    
    # æª¢æŸ¥æ˜¯å¦ç‚º Unnamed æ¬„ä½
    if 'unnamed' in column_name.lower():
        return False
    
    # æª¢æŸ¥æ˜¯å¦åŒ…å«è‹±æ–‡æ–‡å­—ï¼ˆè‡³å°‘ä¸€å€‹è‹±æ–‡å­—æ¯ï¼‰
    if not re.search(r'[a-zA-Z]', column_name):
        return False
    
    return True

def is_valid_order_sn(order_sn: str) -> bool:
    """æª¢æŸ¥ order_sn æ˜¯å¦ç‚ºæœ‰æ•ˆçš„è¨‚å–®ç·¨è™Ÿ"""
    # ç§»é™¤ç©ºç™½ä¸¦è½‰æ›ç‚ºå­—ä¸²
    order_sn = str(order_sn).strip()
    
    # æª¢æŸ¥æ˜¯å¦ç‚ºç©ºæˆ– NaN
    if not order_sn or order_sn.lower() in ['nan', 'none', 'null', '']:
        return False
    
    # æª¢æŸ¥æ˜¯å¦ç‚ºç´”æ•¸å­—ï¼ˆéŠ·å”®å ±è¡¨çš„è¨‚å–®ç·¨è™Ÿé€šå¸¸æ˜¯ç´”æ•¸å­—ï¼‰
    if re.match(r'^\d+$', order_sn):
        return True
    
    # æª¢æŸ¥æ˜¯å¦åªåŒ…å«è‹±æ–‡æ–‡å­—å’Œæ•¸å­—
    if re.match(r'^[a-zA-Z0-9]+$', order_sn):
        return True
    
    return False

def clean_order_report_file(file_path: Path, temp_dir: Path) -> bool:
    """æ¸…æ´—å–®å€‹è¨‚å–®å ±è¡¨æª”æ¡ˆ"""
    try:
        logging.info(f"é–‹å§‹æ¸…æ´—æª”æ¡ˆï¼š{file_path.name}")
        
        # è®€å– CSV æª”æ¡ˆï¼Œå¼·åˆ¶æ‰€æœ‰æ¬„ä½ç‚ºå­—ä¸²é¡å‹
        df = pd.read_csv(file_path, encoding='utf-8-sig', dtype=str)
        
        # è¨˜éŒ„åŸå§‹æ¬„ä½æ•¸é‡
        original_columns = len(df.columns)
        logging.info(f"åŸå§‹æ¬„ä½æ•¸é‡ï¼š{original_columns}")
        
        # éŠ·å”®å ±è¡¨åŸå§‹æ¬„ä½å°æ‡‰ï¼ˆæŒ‰ç…§åŸå§‹é †åºï¼‰
        sales_report_mapping = {
            'è¨‚å–®æ—¥æœŸ': 'order_date',
            'è¨‚å–®ç·¨è™Ÿ': 'order_sn',
            'é …æ¬¡': 'item_no',
            'é…é€ç‹€æ…‹': 'delivery_status',
            'è¨‚å–®ç‹€æ…‹': 'order_status',
            'å•†å“å±¬æ€§': 'product_type',
            'éŠ·å”®ç·¨è™Ÿ': 'sales_no',
            'å­å•†å“éŠ·å”®ç·¨è™Ÿ': 'sub_sales_no',
            'å­å•†å“å•†å“ç·¨è™Ÿ': 'seller_product_sn',
            'é…é€æ–¹å¼': 'delivery_method',
            'å•†å“åç¨±': 'product_name_platform',
            'é¡è‰²': 'color',
            'æ¬¾å¼': 'style',
            'å”®åƒ¹': 'unit_price',
            'æˆæœ¬': 'cost_to_platform',
            'æ•¸é‡': 'quantity',
            'é€šè·¯': 'platform',
            'é…é€ç¢ºèªæ—¥': 'delivery_confirm_date',
            'å…¬å¸': 'delivery_company'
        }
        
        # éœ€è¦æ·»åŠ çš„ç©ºæ¬„ä½
        additional_columns = {
            'customer_name': '',
            'shipping_address': '',
            'customer_day_phone': '',
            'note': '',
            'order_amount': ''
        }
        
        # å»ºç«‹æ–°çš„ DataFrame ä¾†å­˜æ”¾å°æ‡‰å¾Œçš„æ¬„ä½ï¼Œä¿æŒåŸå§‹æ¬„ä½é †åº
        df_cleaned = pd.DataFrame()
        
        # æŒ‰ç…§åŸå§‹éŠ·å”®å ±è¡¨çš„æ¬„ä½é †åºé€²è¡Œå°æ‡‰
        for original_col in df.columns:
            # æª¢æŸ¥æ˜¯å¦æœ‰å°æ‡‰çš„ç›®æ¨™æ¬„ä½
            target_col = sales_report_mapping.get(original_col)
            
            if target_col:
                df_cleaned[target_col] = df[original_col]
                logging.info(f"å°æ‡‰æ¬„ä½ï¼š{original_col} -> {target_col}")
            else:
                # å¦‚æœæ²’æœ‰å°æ‡‰çš„ç›®æ¨™æ¬„ä½ï¼Œè·³éæ­¤æ¬„ä½
                logging.info(f"è·³éæ¬„ä½ï¼š{original_col}")
        
        # ç‚ºç¼ºå°‘çš„ç›®æ¨™æ¬„ä½æ·»åŠ ç©ºæ¬„ä½
        for target_col, default_value in additional_columns.items():
            if target_col not in df_cleaned.columns:
                df_cleaned[target_col] = default_value
                logging.info(f"æ·»åŠ ç©ºæ¬„ä½ï¼š{target_col}")
        
        # ä¿æŒåŸå§‹æ¬„ä½é †åºï¼Œä¸é‡æ–°æ’åº
        
        # è¨˜éŒ„æ¸…æ´—å¾Œçš„æ¬„ä½æ•¸é‡
        cleaned_columns = len(df_cleaned.columns)
        logging.info(f"æ¸…æ´—å¾Œæ¬„ä½æ•¸é‡ï¼š{cleaned_columns}")
        logging.info(f"ç§»é™¤æ¬„ä½æ•¸é‡ï¼š{original_columns - cleaned_columns}")
        
        # ç§»é™¤å®Œå…¨ç©ºç™½çš„è¡Œ
        original_rows = len(df_cleaned)
        df_cleaned = df_cleaned.dropna(how='all')
        cleaned_rows = len(df_cleaned)
        
        if original_rows != cleaned_rows:
            logging.info(f"ç§»é™¤ç©ºç™½è¡Œï¼š{original_rows - cleaned_rows} è¡Œ")
        
        # è™•ç†ç©ºå€¼ï¼Œç¢ºä¿æ‰€æœ‰è³‡æ–™éƒ½æ˜¯å­—ä¸²æ ¼å¼
        df_cleaned = df_cleaned.replace(['nan', 'None', 'NULL', 'null', 'NaN', 'NAN', 'NaT'], '')
        df_cleaned = df_cleaned.fillna('')
        
        # è™•ç† order_date æ¬„ä½è½‰æ›ç‚º DATE è³‡æ–™å‹æ…‹
        if 'order_date' in df_cleaned.columns:
            try:
                # å…ˆè½‰æ›ç‚ºå­—ä¸²ä¸¦æ¸…ç†
                df_cleaned['order_date'] = df_cleaned['order_date'].astype(str)
                df_cleaned['order_date'] = df_cleaned['order_date'].str.strip()
                
                # è½‰æ›ç‚ºæ—¥æœŸæ ¼å¼
                df_cleaned['order_date'] = pd.to_datetime(df_cleaned['order_date'], errors='coerce')
                
                # æ ¼å¼åŒ–ç‚º YYYY-MM-DD
                df_cleaned['order_date'] = df_cleaned['order_date'].dt.strftime('%Y-%m-%d')
                
                # å°‡ NaT è½‰æ›ç‚ºç©ºå­—ä¸²
                df_cleaned['order_date'] = df_cleaned['order_date'].fillna('')
                
                logging.info("å·²å°‡ order_date è½‰æ›ç‚º DATE è³‡æ–™å‹æ…‹")
            except Exception as e:
                logging.warning(f"è½‰æ› order_date æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                # å¦‚æœè½‰æ›å¤±æ•—ï¼Œä¿æŒç‚ºå­—ä¸²æ ¼å¼
                df_cleaned['order_date'] = df_cleaned['order_date'].astype(str)
        
        # å…¶ä»–æ¬„ä½å¼·åˆ¶è½‰æ›ç‚ºå­—ä¸²é¡å‹ï¼Œé¿å…æ•¸å­—è‡ªå‹•è½‰æ›
        for col in df_cleaned.columns:
            if col != 'order_date':  # order_date å·²ç¶“è™•ç†éäº†
                df_cleaned[col] = df_cleaned[col].astype(str)
        
        # å»é™¤æ›è¡Œç¬¦è™Ÿå’Œå¤šé¤˜ç©ºç™½
        for col in df_cleaned.columns:
            df_cleaned[col] = df_cleaned[col].str.replace(r'\n|\r|\r\n', ' ', regex=True)
            df_cleaned[col] = df_cleaned[col].str.replace(r'\s+', ' ', regex=True)
            df_cleaned[col] = df_cleaned[col].str.strip()
        
        # æ³¨æ„ï¼šæ—¥æœŸæ™‚é–“åˆ†é›¢å·²åœ¨è…³æœ¬ 01 ä¸­è™•ç†ï¼Œæ­¤è™•ä¸å†éœ€è¦
        
        # æª¢æŸ¥ order_sn æ¬„ä½ä¸¦æ’é™¤ç„¡æ•ˆçš„æ•´ç­†è³‡æ–™
        if 'order_sn' in df_cleaned.columns:
            original_rows_before_filter = len(df_cleaned)
            
            # éæ¿¾æ‰ order_sn ä¸æ˜¯è‹±æ–‡æˆ–æ•¸å­—çš„æ•´ç­†è³‡æ–™
            df_cleaned = df_cleaned[df_cleaned['order_sn'].apply(is_valid_order_sn)]
            
            filtered_rows = len(df_cleaned)
            removed_rows = original_rows_before_filter - filtered_rows
            
            if removed_rows > 0:
                logging.info(f"ç§»é™¤ order_sn ç„¡æ•ˆçš„è³‡æ–™ï¼š{removed_rows} ç­†")
                logging.info(f"å‰©é¤˜æœ‰æ•ˆè³‡æ–™ï¼š{filtered_rows} ç­†")
        else:
            logging.warning("æœªæ‰¾åˆ° order_sn æ¬„ä½ï¼Œè·³é order_sn é©—è­‰")
        
        # å»ºç«‹ temp ç›®éŒ„çµæ§‹
        # è¨ˆç®—ç›¸å°è·¯å¾‘ï¼šå¾ data_raw/etmall/sales_report é–‹å§‹
        sales_report_index = None
        for i, part in enumerate(file_path.parts):
            if part == 'sales_report':
                sales_report_index = i
                break
        
        if sales_report_index is None:
            raise ValueError(f"ç„¡æ³•åœ¨è·¯å¾‘ä¸­æ‰¾åˆ° 'sales_report' ç›®éŒ„ï¼š{file_path}")
        
        # å¾ sales_report ä¹‹å¾Œçš„è·¯å¾‘éƒ¨åˆ†ï¼ˆè·³é sales_report ç›®éŒ„ï¼‰
        relative_parts = file_path.parts[sales_report_index + 1:]
        temp_file_path = temp_dir / Path(*relative_parts)
        
        # ç¢ºä¿ç›®æ¨™ç›®éŒ„å­˜åœ¨
        temp_file_path.parent.mkdir(parents=True, exist_ok=True)
        
        # å„²å­˜æ¸…æ´—å¾Œçš„æª”æ¡ˆåˆ° temp ç›®éŒ„ï¼Œç¢ºä¿æ‰€æœ‰è³‡æ–™éƒ½æ˜¯å­—ä¸²æ ¼å¼
        df_cleaned.to_csv(temp_file_path, index=False, encoding='utf-8-sig', na_rep='')
        logging.info(f"âœ… æª”æ¡ˆæ¸…æ´—å®Œæˆï¼š{file_path.name}")
        logging.info(f"   è¼¸å‡ºä½ç½®ï¼š{temp_file_path}")
        logging.info(f"   ä¿ç•™æ¬„ä½ï¼š{list(df_cleaned.columns)}")
        logging.info(f"   è³‡æ–™é¡å‹ï¼šæ‰€æœ‰æ¬„ä½å·²å¼·åˆ¶è½‰æ›ç‚ºå­—ä¸²æ ¼å¼")
        logging.info(f"   æœ€çµ‚è³‡æ–™ç­†æ•¸ï¼š{len(df_cleaned)} ç­†")
        
        return True
        
    except Exception as e:
        logging.error(f"æ¸…æ´—æª”æ¡ˆ {file_path.name} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return False

def find_sales_report_files(sales_report_dir: Path) -> List[Path]:
    """å°‹æ‰¾ sales_report ç›®éŒ„ä¸‹çš„æ‰€æœ‰ CSV æª”æ¡ˆ"""
    csv_files = []
    
    # éè¿´æœå°‹æ‰€æœ‰ CSV æª”æ¡ˆ
    for file_path in sales_report_dir.rglob("*.csv"):
        # æ’é™¤å‚™ä»½æª”æ¡ˆ
        if 'backup' not in file_path.name.lower():
            csv_files.append(file_path)
    
    return csv_files

def main() -> None:
    """ä¸»å‡½æ•¸"""
    setup_logging()
    
    # å–å¾—å°ˆæ¡ˆæ ¹ç›®éŒ„
    project_root = Path(__file__).resolve().parents[2]
    sales_report_dir = project_root / 'data_raw' / 'etmall' / 'sales_report'
    temp_dir = project_root / 'temp' / 'etmall' / 'Sales_Report'
    
    logging.info(f'å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼š{project_root}')
    logging.info(f'éŠ·å”®å ±è¡¨ç›®éŒ„ï¼š{sales_report_dir}')
    logging.info(f'è¼¸å‡ºç›®éŒ„ï¼š{temp_dir}')
    
    # æª¢æŸ¥ç›®éŒ„æ˜¯å¦å­˜åœ¨
    if not sales_report_dir.exists():
        logging.error(f"éŠ·å”®å ±è¡¨ç›®éŒ„ä¸å­˜åœ¨ï¼š{sales_report_dir}")
        return
    
    # å»ºç«‹ temp ç›®éŒ„
    temp_dir.mkdir(parents=True, exist_ok=True)
    logging.info(f"å·²å»ºç«‹è¼¸å‡ºç›®éŒ„ï¼š{temp_dir}")
    
    # å°‹æ‰¾æ‰€æœ‰ CSV æª”æ¡ˆ
    csv_files = find_sales_report_files(sales_report_dir)
    
    if not csv_files:
        logging.info("æ²’æœ‰æ‰¾åˆ°éœ€è¦æ¸…æ´—çš„ CSV æª”æ¡ˆ")
        return
    
    logging.info(f"æ‰¾åˆ° {len(csv_files)} å€‹ CSV æª”æ¡ˆéœ€è¦æ¸…æ´—")
    
    # æ¸…æ´—æ¯å€‹æª”æ¡ˆ
    success_count = 0
    failed_count = 0
    
    for file_path in csv_files:
        logging.info(f"\n{'='*50}")
        if clean_order_report_file(file_path, temp_dir):
            success_count += 1
        else:
            failed_count += 1
    
    # ç¸½çµ
    logging.info(f"\n{'='*50}")
    logging.info("ğŸ“Š æ¸…æ´—çµæœç¸½çµï¼š")
    logging.info(f"   - æˆåŠŸæ¸…æ´—ï¼š{success_count} å€‹æª”æ¡ˆ")
    logging.info(f"   - æ¸…æ´—å¤±æ•—ï¼š{failed_count} å€‹æª”æ¡ˆ")
    logging.info(f"   - ç¸½è¨ˆè™•ç†ï¼š{len(csv_files)} å€‹æª”æ¡ˆ")
    logging.info(f"   - è¼¸å‡ºç›®éŒ„ï¼š{temp_dir}")
    
    if success_count > 0:
        logging.info("âœ… éŠ·å”®å ±è¡¨æ¸…æ´—å®Œæˆï¼")
    else:
        logging.error("âŒ æ²’æœ‰æˆåŠŸæ¸…æ´—ä»»ä½•æª”æ¡ˆ")
        sys.exit(1)

if __name__ == '__main__':
    main()
